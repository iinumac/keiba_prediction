"""
HTMLãƒ‘ãƒ¼ã‚µãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆæ‹¡å¼µç‰ˆï¼‰

netkeibaã®ãƒ¬ãƒ¼ã‚¹çµæœHTMLã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦å…¨ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹
"""

import re
from pathlib import Path
from bs4 import BeautifulSoup
from typing import Dict, List, Optional, Tuple


def classify_race_level(prize_money: float) -> Tuple[str, int]:
    """
    1ç€è³é‡‘ã‹ã‚‰ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã‚’åˆ†é¡
    
    Args:
        prize_money: 1ç€è³é‡‘ï¼ˆä¸‡å††ï¼‰
    
    Returns:
        (level, score): ãƒ¬ãƒ™ãƒ«ï¼ˆS/A/B/C/D/Eï¼‰ã¨ã‚¹ã‚³ã‚¢ï¼ˆ6-1ï¼‰
    """
    if prize_money >= 10000:
        return 'S', 6  # G1
    elif prize_money >= 5000:
        return 'A', 5  # G2
    elif prize_money >= 3000:
        return 'B', 4  # G3, ãƒªã‚¹ãƒ†ãƒƒãƒ‰
    elif prize_money >= 1500:
        return 'C', 3  # ã‚ªãƒ¼ãƒ—ãƒ³, 3å‹ã‚¯ãƒ©ã‚¹
    elif prize_money >= 750:
        return 'D', 2  # 2å‹, 1å‹ã‚¯ãƒ©ã‚¹
    else:
        return 'E', 1  # æ–°é¦¬, æœªå‹åˆ©


def parse_time_to_seconds(time_str: str) -> Optional[float]:
    """
    ã‚¿ã‚¤ãƒ æ–‡å­—åˆ—ã‚’ç§’æ•°ã«å¤‰æ›
    
    Args:
        time_str: "1:08.8" å½¢å¼ã®ã‚¿ã‚¤ãƒ 
    
    Returns:
        ç§’æ•°ï¼ˆfloatï¼‰ã¾ãŸã¯ None
    """
    if not time_str:
        return None
    
    try:
        match = re.match(r'(\d+):(\d+)\.(\d+)', time_str)
        if match:
            minutes = int(match.group(1))
            seconds = int(match.group(2))
            decimals = int(match.group(3))
            return minutes * 60 + seconds + decimals / 10
    except:
        pass
    
    return None


def parse_horse_weight(weight_str: str) -> Tuple[Optional[int], Optional[int]]:
    """
    é¦¬ä½“é‡æ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹
    
    Args:
        weight_str: "462(-2)" å½¢å¼
    
    Returns:
        (ä½“é‡, å¢—æ¸›) ã®ã‚¿ãƒ—ãƒ«
    """
    if not weight_str:
        return None, None
    
    try:
        match = re.match(r'(\d+)\(([\+\-]?\d+)\)', weight_str.strip())
        if match:
            weight = int(match.group(1))
            change = int(match.group(2))
            return weight, change
    except:
        pass
    
    return None, None


def parse_passing_order(passing_str: str) -> Optional[List[int]]:
    """
    é€šéé †ã‚’ãƒ‘ãƒ¼ã‚¹
    
    Args:
        passing_str: "1-1" ã‚„ "3-3-2-1" å½¢å¼
    
    Returns:
        é€šéé †ãƒªã‚¹ãƒˆ
    """
    if not passing_str:
        return None
    
    try:
        parts = passing_str.strip().split('-')
        return [int(p) for p in parts if p.isdigit()]
    except:
        return None


def parse_race_html_full(html_path: Path) -> Dict:
    """
    ãƒ¬ãƒ¼ã‚¹HTMLã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦å…¨ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    
    Args:
        html_path: HTMLãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    
    Returns:
        dict: {
            'race_info': ãƒ¬ãƒ¼ã‚¹æƒ…å ±,
            'horses': å‡ºèµ°é¦¬ãƒªã‚¹ãƒˆ
        }
    """
    with open(html_path, 'r', encoding='utf-8') as f:
        soup = BeautifulSoup(f.read(), 'html.parser')
    
    race_id = Path(html_path).stem
    
    # ============ ãƒ¬ãƒ¼ã‚¹æƒ…å ± ============
    race_info = {
        'race_id': race_id,
        'venue_code': race_id[4:6] if len(race_id) >= 6 else None,  # ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰
        'kaisai': race_id[6:8] if len(race_id) >= 8 else None,     # é–‹å‚¬å›
        'day': race_id[8:10] if len(race_id) >= 10 else None,       # é–‹å‚¬æ—¥
        'race_num': race_id[10:12] if len(race_id) >= 12 else None, # ãƒ¬ãƒ¼ã‚¹ç•ªå·
    }
    
    # ç«¶é¦¬å ´åãƒãƒƒãƒ”ãƒ³ã‚°
    venue_map = {
        '01': 'æœ­å¹Œ', '02': 'å‡½é¤¨', '03': 'ç¦å³¶', '04': 'æ–°æ½Ÿ', '05': 'æ±äº¬',
        '06': 'ä¸­å±±', '07': 'ä¸­äº¬', '08': 'äº¬éƒ½', '09': 'é˜ªç¥', '10': 'å°å€‰'
    }
    race_info['venue_name'] = venue_map.get(race_info['venue_code'], '')
    
    # ãƒ¬ãƒ¼ã‚¹åãƒ»è©³ç´°
    race_data = soup.find('dl', class_='racedata')
    if race_data:
        h1 = race_data.find('h1')
        race_info['race_name'] = h1.text.strip() if h1 else ''
        
        span = race_data.find('span')
        if span:
            info_text = span.text.strip()
            
            # è·é›¢ãƒ»ã‚³ãƒ¼ã‚¹
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ä¾‹: "èŠå³1600m", "ãƒ€å³1200m", "èŠå³ å¤–1600m", "èŠå·¦ å†…2000m", "éšœèŠ3000m"
            match = re.search(r'(éšœ)?(èŠ|ãƒ€(?:ãƒ¼ãƒˆ)?)\s*(å³|å·¦)?\s*(å¤–|å†…|ç›´)?(?:\s*(å¤–|å†…|ç›´))?\s*(\d+)m', info_text)
            if match:
                is_obstacle = match.group(1) is not None  # éšœå®³ãƒ¬ãƒ¼ã‚¹
                surface = match.group(2)
                race_info['surface'] = 'ãƒ€ãƒ¼ãƒˆ' if surface.startswith('ãƒ€') else surface
                race_info['direction'] = match.group(3) or ''
                # å¤–/å†…/ç›´ ã¯ group(4) ã¾ãŸã¯ group(5) ã«å…¥ã‚‹
                course_type = match.group(4) or match.group(5) or ''
                race_info['course_type'] = course_type
                race_info['distance'] = int(match.group(6))
            
            # å¤©å€™
            weather_match = re.search(r'å¤©å€™\s*[:ï¼š]\s*(\S+)', info_text)
            race_info['weather'] = weather_match.group(1) if weather_match else ''
            
            # é¦¬å ´çŠ¶æ…‹
            condition_match = re.search(r'(èŠ|ãƒ€ãƒ¼ãƒˆ)\s*[:ï¼š]\s*(\S+)', info_text)
            race_info['track_condition'] = condition_match.group(2) if condition_match else ''
            
            # ç™ºèµ°æ™‚åˆ»
            time_match = re.search(r'ç™ºèµ°\s*[:ï¼š]\s*(\d+:\d+)', info_text)
            race_info['start_time'] = time_match.group(1) if time_match else ''
    
    # æ—¥ä»˜ãƒ»è©³ç´°æƒ…å ±
    date_elem = soup.find('p', class_='smalltxt')
    if date_elem:
        date_text = date_elem.text
        
        date_match = re.search(r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', date_text)
        if date_match:
            race_info['date'] = f"{date_match.group(1)}-{int(date_match.group(2)):02d}-{int(date_match.group(3)):02d}"
            race_info['year'] = int(date_match.group(1))
            race_info['month'] = int(date_match.group(2))
        
        # ã‚¯ãƒ©ã‚¹æƒ…å ±ã‚’æŠ½å‡º
        race_info['class_info'] = date_text.strip()
    
    # ============ å‡ºèµ°é¦¬æƒ…å ± ============
    horses = []
    result_table = soup.find('table', class_='race_table_01')
    
    if result_table:
        rows = result_table.find_all('tr')[1:]  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚¹ã‚­ãƒƒãƒ—
        
        for row in rows:
            cells = row.find_all('td')
            if len(cells) < 10:
                continue
            
            horse = {'race_id': race_id}
            
            # åŸºæœ¬æƒ…å ±ã®ã‚»ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            # 0:ç€é †, 1:æ ç•ª, 2:é¦¬ç•ª, 3:é¦¬å, 4:æ€§é½¢, 5:æ–¤é‡, 6:é¨æ‰‹, 7:ã‚¿ã‚¤ãƒ , 8:ç€å·®
            
            # ç€é †
            finish = cells[0].text.strip()
            horse['finish_position'] = int(finish) if finish.isdigit() else None
            horse['is_finished'] = finish.isdigit()
            horse['dnf_reason'] = finish if not finish.isdigit() else None  # ä¸­æ­¢, é™¤å¤– ç­‰
            
            # æ ç•ªãƒ»é¦¬ç•ª
            gate = cells[1].text.strip()
            horse['gate_number'] = int(gate) if gate.isdigit() else None
            
            num = cells[2].text.strip()
            horse['horse_number'] = int(num) if num.isdigit() else None
            
            # é¦¬åãƒ»é¦¬ID
            horse_link = cells[3].find('a')
            if horse_link:
                horse['horse_name'] = horse_link.text.strip()
                href = horse_link.get('href', '')
                match = re.search(r'/horse/(\d+)/', href)
                horse['horse_id'] = match.group(1) if match else None
            
            # æ€§é½¢
            sex_age = cells[4].text.strip()
            if sex_age:
                horse['sex'] = sex_age[0] if sex_age else ''
                horse['age'] = int(sex_age[1:]) if len(sex_age) > 1 and sex_age[1:].isdigit() else None
            
            # æ–¤é‡
            try:
                horse['impost'] = float(cells[5].text.strip())
            except ValueError:
                horse['impost'] = None
            
            # é¨æ‰‹
            jockey_link = cells[6].find('a')
            if jockey_link:
                horse['jockey_name'] = jockey_link.text.strip()
                href = jockey_link.get('href', '')
                match = re.search(r'/jockey/result/recent/(\d+)/', href)
                horse['jockey_id'] = match.group(1) if match else None
            
            # ã‚¿ã‚¤ãƒ 
            time_str = cells[7].text.strip()
            horse['time_str'] = time_str
            horse['time_seconds'] = parse_time_to_seconds(time_str)
            
            # ç€å·®
            horse['margin'] = cells[8].text.strip()
            
            # diary_snap_cut å†…ã®è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ã™
            # é€šéé †ã€ä¸ŠãŒã‚Š3F ã¯ã‚»ãƒ«å†…ã® diary_snap_cut ã‚¿ã‚°ã®ä¸­ã«ã‚ã‚‹
            snap_cut = row.find('diary_snap_cut')
            if snap_cut:
                snap_cells = snap_cut.find_all('td')
                for sc in snap_cells:
                    text = sc.text.strip()
                    # é€šéé †ï¼ˆä¾‹: "1-1", "3-3-2"ï¼‰
                    if '-' in text and all(p.isdigit() for p in text.split('-')):
                        horse['passing_order'] = text
                        passing_list = parse_passing_order(text)
                        if passing_list:
                            horse['first_corner'] = passing_list[0] if len(passing_list) > 0 else None
                            horse['last_corner'] = passing_list[-1] if len(passing_list) > 0 else None
                    # ä¸ŠãŒã‚Š3Fï¼ˆä¾‹: "33.9"ï¼‰
                    elif re.match(r'^\d+\.\d+$', text):
                        try:
                            horse['last_3f'] = float(text)
                        except:
                            pass
            
            # ã‚ªãƒƒã‚ºãƒ»äººæ°—ï¼ˆdiary_snap_cutå¤–ã®ã‚»ãƒ«ã‹ã‚‰ï¼‰
            # ã‚»ãƒ«ã®é †åºãŒç•°ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ã‚¯ãƒ©ã‚¹åã§åˆ¤å®š
            for cell in cells:
                text = cell.text.strip()
                classes = cell.get('class', [])
                
                # å˜å‹ã‚ªãƒƒã‚º
                if 'txt_r' in classes and re.match(r'^\d+\.\d+$', text):
                    try:
                        if 'odds' not in horse:
                            horse['odds'] = float(text)
                    except:
                        pass
                
                # äººæ°—
                if any('ml' in c for c in classes):
                    span = cell.find('span')
                    if span and span.text.strip().isdigit():
                        pop = int(span.text.strip())
                        if 1 <= pop <= 18:
                            horse['popularity'] = pop
            
            # é¦¬ä½“é‡ï¼ˆä¾‹: "462(-2)"ï¼‰
            for cell in cells:
                text = cell.text.strip()
                if re.match(r'^\d+\([\+\-]?\d+\)$', text):
                    weight, change = parse_horse_weight(text)
                    horse['horse_weight'] = weight
                    horse['weight_change'] = change
                    break
            
            # èª¿æ•™å¸«
            trainer_cell = None
            for cell in cells:
                if '[æ±]' in cell.text or '[è¥¿]' in cell.text:
                    trainer_cell = cell
                    break
            
            if trainer_cell:
                trainer_link = trainer_cell.find('a')
                if trainer_link:
                    horse['trainer_name'] = trainer_link.text.strip()
                    href = trainer_link.get('href', '')
                    match = re.search(r'/trainer/result/recent/(\d+)/', href)
                    horse['trainer_id'] = match.group(1) if match else None
                
                horse['trainer_region'] = 'æ±' if '[æ±]' in trainer_cell.text else 'è¥¿'
            
            # é¦¬ä¸»
            for cell in cells:
                owner_link = cell.find('a', href=re.compile(r'/owner/'))
                if owner_link:
                    horse['owner_name'] = owner_link.text.strip()
                    href = owner_link.get('href', '')
                    match = re.search(r'/owner/result/recent/(\d+)/', href)
                    horse['owner_id'] = match.group(1) if match else None
                    break
            
            # è³é‡‘ï¼ˆæœ€å¾Œã®ã‚»ãƒ«ï¼‰- ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã«å¯¾å¿œ
            prize_text = cells[-1].text.strip().replace(',', '')
            try:
                horse['prize_money'] = float(prize_text)
            except ValueError:
                horse['prize_money'] = 0.0
            
            horses.append(horse)
    
    # ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«ã‚’1ç€è³é‡‘ã‹ã‚‰åˆ¤å®š
    if horses:
        first_place = [h for h in horses if h.get('finish_position') == 1]
        if first_place:
            first_prize = first_place[0].get('prize_money', 0)
            race_info['first_prize'] = first_prize
            level, score = classify_race_level(first_prize)
            race_info['race_level'] = level
            race_info['level_score'] = score
        
        # å‡ºèµ°é ­æ•°
        race_info['horse_count'] = len(horses)
    
    return {'race_info': race_info, 'horses': horses}


def parse_multiple_html_full(
    html_dir: Path,
    years: Optional[List[int]] = None,
    progress_callback=None,
    existing_race_ids: Optional[set] = None,
    limit_per_year: Optional[int] = None
) -> Tuple[List[Dict], List[Dict]]:
    """
    è¤‡æ•°HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬ãƒ‘ãƒ¼ã‚¹ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºç‰ˆï¼‰
    
    Args:
        html_dir: HTMLãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        years: å¯¾è±¡å¹´ãƒªã‚¹ãƒˆï¼ˆNoneã§å…¨å¹´ï¼‰
        progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
        existing_race_ids: æ—¢å­˜ã®race_idã‚»ãƒƒãƒˆï¼ˆå·®åˆ†æ›´æ–°ç”¨ï¼‰
        limit_per_year: å„å¹´ã®å‡¦ç†ä»¶æ•°ä¸Šé™ï¼ˆé–‹ç™ºç”¨ã€‚Noneã§ç„¡åˆ¶é™ï¼‰
    
    Returns:
        (race_list, horse_list): ãƒ¬ãƒ¼ã‚¹æƒ…å ±ãƒªã‚¹ãƒˆã¨é¦¬æƒ…å ±ãƒªã‚¹ãƒˆ
    """
    race_list = []
    horse_list = []
    skipped = 0
    
    if years is None:
        year_dirs = sorted([d for d in html_dir.glob('*') if d.is_dir()])
    else:
        year_dirs = [html_dir / str(y) for y in years if (html_dir / str(y)).exists()]
    
    # limit_per_year ãŒã‚ã‚‹å ´åˆã¯æ¦‚ç®—
    if limit_per_year:
        total_files = len(year_dirs) * limit_per_year
    else:
        total_files = sum(len(list(d.glob('*.html'))) for d in year_dirs if d.is_dir())
    
    processed = 0
    
    for year_dir in year_dirs:
        if not year_dir.is_dir():
            continue
        
        year_count = 0  # ã“ã®å¹´ã®å‡¦ç†ä»¶æ•°
        
        for html_file in sorted(year_dir.glob('*.html')):
            # å¹´ã”ã¨ã®ä¸Šé™ãƒã‚§ãƒƒã‚¯
            if limit_per_year and year_count >= limit_per_year:
                break
            
            race_id = html_file.stem
            
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if existing_race_ids and race_id in existing_race_ids:
                skipped += 1
                processed += 1
                continue
            
            try:
                result = parse_race_html_full(html_file)
                race_list.append(result['race_info'])
                
                # å„é¦¬ã«ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’è¿½åŠ 
                for horse in result['horses']:
                    horse['race_level'] = result['race_info'].get('race_level')
                    horse['level_score'] = result['race_info'].get('level_score')
                    horse['race_date'] = result['race_info'].get('date')
                    horse['venue_code'] = result['race_info'].get('venue_code')
                    horse['venue_name'] = result['race_info'].get('venue_name')
                    horse['distance'] = result['race_info'].get('distance')
                    horse['surface'] = result['race_info'].get('surface')
                    horse['track_condition'] = result['race_info'].get('track_condition')
                    horse_list.append(horse)
                
                processed += 1
                year_count += 1
                
                if progress_callback and processed % 100 == 0:
                    progress_callback(processed, total_files, skipped)
                    
            except Exception as e:
                print(f"Error parsing {html_file}: {e}")
                processed += 1
                year_count += 1
    
    if progress_callback:
        progress_callback(processed, total_files, skipped)
    
    return race_list, horse_list


def parse_incremental(
    html_dir: Path,
    races_csv: Path,
    results_csv: Path,
    years: Optional[List[int]] = None,
    progress_callback=None
) -> Tuple[int, int]:
    """
    å·®åˆ†æ›´æ–°: æ–°è¦HTMLã®ã¿ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æ—¢å­˜CSVã«è¿½åŠ 
    
    Args:
        html_dir: HTMLãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        races_csv: æ—¢å­˜ã®races.csvãƒ‘ã‚¹
        results_csv: æ—¢å­˜ã®results.csvãƒ‘ã‚¹
        years: å¯¾è±¡å¹´ãƒªã‚¹ãƒˆï¼ˆNoneã§å…¨å¹´ï¼‰
        progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
    
    Returns:
        (new_races, new_horses): æ–°è¦è¿½åŠ ã•ã‚ŒãŸãƒ¬ãƒ¼ã‚¹æ•°ã¨é¦¬ãƒ‡ãƒ¼ã‚¿æ•°
    """
    import pandas as pd
    
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    existing_race_ids = set()
    if races_csv.exists():
        existing_df = pd.read_csv(races_csv, usecols=['race_id'], dtype={'race_id': str})
        existing_race_ids = set(existing_df['race_id'].astype(str).tolist())
        print(f"æ—¢å­˜ãƒ¬ãƒ¼ã‚¹æ•°: {len(existing_race_ids):,}")
    
    # æ–°è¦HTMLã®ã¿ãƒ‘ãƒ¼ã‚¹
    new_races, new_horses = parse_multiple_html_full(
        html_dir,
        years=years,
        progress_callback=progress_callback,
        existing_race_ids=existing_race_ids
    )
    
    if len(new_races) == 0:
        print("æ–°è¦ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“")
        return 0, 0
    
    # æ–°è¦ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
    new_races_df = pd.DataFrame(new_races)
    new_results_df = pd.DataFrame(new_horses)
    
    # æ—¢å­˜CSVã«è¿½è¨˜
    if races_csv.exists():
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§çµåˆ
        existing_races_df = pd.read_csv(races_csv)
        existing_results_df = pd.read_csv(results_csv)
        
        combined_races_df = pd.concat([existing_races_df, new_races_df], ignore_index=True)
        combined_results_df = pd.concat([existing_results_df, new_results_df], ignore_index=True)
        
        combined_races_df.to_csv(races_csv, index=False, encoding='utf-8')
        combined_results_df.to_csv(results_csv, index=False, encoding='utf-8')
    else:
        # æ–°è¦ä½œæˆ
        new_races_df.to_csv(races_csv, index=False, encoding='utf-8')
        new_results_df.to_csv(results_csv, index=False, encoding='utf-8')
    
    return len(new_races), len(new_horses)


def parse_incremental_parquet(
    html_dir: Path,
    races_parquet: Path,
    results_parquet: Path,
    years: Optional[List[int]] = None,
    limit_per_year: Optional[int] = None,
    progress_callback=None
) -> Tuple[int, int]:
    """
    å·®åˆ†æ›´æ–°: æ–°è¦HTMLã®ã¿ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦æ—¢å­˜Parquetã«è¿½åŠ 
    
    Args:
        html_dir: HTMLãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        races_parquet: æ—¢å­˜ã®races.parquetãƒ‘ã‚¹
        results_parquet: æ—¢å­˜ã®results.parquetãƒ‘ã‚¹
        years: å¯¾è±¡å¹´ãƒªã‚¹ãƒˆï¼ˆNoneã§å…¨å¹´ï¼‰
        limit_per_year: å„å¹´ã®å‡¦ç†ä»¶æ•°ä¸Šé™ï¼ˆé–‹ç™ºç”¨ï¼‰
        progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
    
    Returns:
        (new_races, new_horses): æ–°è¦è¿½åŠ ã•ã‚ŒãŸãƒ¬ãƒ¼ã‚¹æ•°ã¨é¦¬ãƒ‡ãƒ¼ã‚¿æ•°
    """
    import pandas as pd
    
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    existing_race_ids = set()
    existing_races_df = None
    existing_results_df = None
    
    if races_parquet.exists():
        existing_races_df = pd.read_parquet(races_parquet)
        existing_race_ids = set(existing_races_df['race_id'].astype(str).tolist())
        existing_results_df = pd.read_parquet(results_parquet)
        print(f"ğŸ“Š æ—¢å­˜ãƒ‡ãƒ¼ã‚¿: {len(existing_race_ids):,} ãƒ¬ãƒ¼ã‚¹")
    
    # æ–°è¦HTMLã®ã¿ãƒ‘ãƒ¼ã‚¹
    new_races, new_horses = parse_multiple_html_full(
        html_dir,
        years=years,
        progress_callback=progress_callback,
        existing_race_ids=existing_race_ids,
        limit_per_year=limit_per_year
    )
    
    if len(new_races) == 0:
        print("â„¹ï¸ æ–°è¦ãƒ¬ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“")
        return 0, 0
    
    # æ–°è¦ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
    new_races_df = pd.DataFrame(new_races)
    new_results_df = pd.DataFrame(new_horses)
    
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨çµåˆ
    if existing_races_df is not None:
        combined_races_df = pd.concat([existing_races_df, new_races_df], ignore_index=True)
        combined_results_df = pd.concat([existing_results_df, new_results_df], ignore_index=True)
    else:
        combined_races_df = new_races_df
        combined_results_df = new_results_df
    
    # Parquetä¿å­˜
    combined_races_df.to_parquet(races_parquet, index=False, compression='snappy')
    combined_results_df.to_parquet(results_parquet, index=False, compression='snappy')
    
    print(f"âœ… æ–°è¦è¿½åŠ : {len(new_races):,} ãƒ¬ãƒ¼ã‚¹, {len(new_horses):,} å‡ºèµ°é¦¬")
    print(f"   åˆè¨ˆ: {len(combined_races_df):,} ãƒ¬ãƒ¼ã‚¹, {len(combined_results_df):,} å‡ºèµ°é¦¬")
    
    return len(new_races), len(new_horses)


# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹
parse_race_html = parse_race_html_full
parse_multiple_html = parse_multiple_html_full
