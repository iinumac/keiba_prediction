{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# S02: ãƒ‡ãƒ¼ã‚¿å¤‰æ›ï¼ˆHTML â†’ Parquetï¼‰\n",
                "\n",
                "HTMLã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦Parquetå½¢å¼ã§ä¿å­˜ãƒ»GitHubã«ãƒ—ãƒƒã‚·ãƒ¥\n",
                "\n",
                "**å®Ÿè¡Œç’°å¢ƒ**: Sagemaker"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. ç’°å¢ƒè¨­å®š"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install pyarrow -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "import pandas as pd\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ\n",
                "PROJECT_ROOT = Path('../../')\n",
                "sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
                "\n",
                "# ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹\n",
                "HTML_DIR = PROJECT_ROOT / 'data' / 'raceHTML'\n",
                "PROCESSED_DIR = PROJECT_ROOT / 'data' / 'processed'\n",
                "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "RACES_PARQUET = PROCESSED_DIR / 'races.parquet'\n",
                "RESULTS_PARQUET = PROCESSED_DIR / 'results.parquet'\n",
                "\n",
                "print(f\"HTML_DIR: {HTML_DIR.resolve()}\")\n",
                "print(f\"å‡ºåŠ›å…ˆ: {PROCESSED_DIR.resolve()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scraper.parser import parse_multiple_html_full\n",
                "print(\"âœ… ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿å®Œäº†\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. ãƒ‘ãƒ¼ã‚¹è¨­å®š\n",
                "\n",
                "**é–‹ç™ºä¸­**: å„å¹´100ä»¶ãšã¤ã§ç¢ºèª  \n",
                "**æœ¬ç•ª**: `LIMIT_PER_YEAR = None` ã§å…¨ä»¶å‡¦ç†"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ========== è¨­å®š ==========\n",
                "\n",
                "# é–‹ç™ºãƒ¢ãƒ¼ãƒ‰: å„å¹´100ä»¶ã«åˆ¶é™\n",
                "LIMIT_PER_YEAR = 100\n",
                "\n",
                "# æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰: å…¨ä»¶å‡¦ç†\n",
                "# LIMIT_PER_YEAR = None\n",
                "\n",
                "print(f\"å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {'é–‹ç™ºï¼ˆå„å¹´' + str(LIMIT_PER_YEAR) + 'ä»¶ï¼‰' if LIMIT_PER_YEAR else 'æœ¬ç•ªï¼ˆå…¨ä»¶ï¼‰'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. HTMLãƒ‘ãƒ¼ã‚¹å®Ÿè¡Œ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def progress_callback(processed, total, skipped=0):\n",
                "    pct = processed / total * 100 if total > 0 else 0\n",
                "    print(f\"\\ré€²æ—: {processed:,}/{total:,} ({pct:.1f}%)\", end='')\n",
                "\n",
                "print(\"ğŸ“Š HTMLãƒ‘ãƒ¼ã‚¹ã‚’é–‹å§‹...\")\n",
                "if LIMIT_PER_YEAR:\n",
                "    print(f\"   âš ï¸ é–‹ç™ºãƒ¢ãƒ¼ãƒ‰: å„å¹´ {LIMIT_PER_YEAR} ä»¶ã¾ã§\")\n",
                "\n",
                "race_list, horse_list = parse_multiple_html_full(\n",
                "    HTML_DIR,\n",
                "    years=None,\n",
                "    progress_callback=progress_callback,\n",
                "    limit_per_year=LIMIT_PER_YEAR\n",
                ")\n",
                "\n",
                "print(f\"\\n\\nâœ… ãƒ‘ãƒ¼ã‚¹å®Œäº†\")\n",
                "print(f\"   ãƒ¬ãƒ¼ã‚¹æ•°: {len(race_list):,}\")\n",
                "print(f\"   å‡ºèµ°é¦¬ãƒ‡ãƒ¼ã‚¿æ•°: {len(horse_list):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DataFrameã«å¤‰æ›\n",
                "races_df = pd.DataFrame(race_list)\n",
                "results_df = pd.DataFrame(horse_list)\n",
                "\n",
                "print(f\"races_df: {races_df.shape}\")\n",
                "print(f\"results_df: {results_df.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Parquetå½¢å¼ã§ä¿å­˜\n",
                "races_df.to_parquet(RACES_PARQUET, index=False, compression='snappy')\n",
                "results_df.to_parquet(RESULTS_PARQUET, index=False, compression='snappy')\n",
                "\n",
                "print(\"âœ… Parquetä¿å­˜å®Œäº†\")\n",
                "print(f\"   races.parquet: {RACES_PARQUET.stat().st_size / 1024 / 1024:.2f} MB\")\n",
                "print(f\"   results.parquet: {RESULTS_PARQUET.stat().st_size / 1024 / 1024:.2f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. ãƒ‡ãƒ¼ã‚¿ç¢ºèª"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=== ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ ===\")\n",
                "print(f\"ãƒ¬ãƒ¼ã‚¹æ•°: {len(races_df):,}\")\n",
                "print(f\"å‡ºèµ°é¦¬ãƒ‡ãƒ¼ã‚¿æ•°: {len(results_df):,}\")\n",
                "\n",
                "if 'year' in races_df.columns:\n",
                "    print(\"\\n=== å¹´åˆ¥ãƒ¬ãƒ¼ã‚¹æ•° ===\")\n",
                "    print(races_df.groupby('year').size().to_string())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=== ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ ã‚µãƒ³ãƒ—ãƒ« ===\")\n",
                "display(races_df.tail(5))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=== å‡ºèµ°é¦¬ãƒ‡ãƒ¼ã‚¿ ã‚µãƒ³ãƒ—ãƒ« ===\")\n",
                "display(results_df.tail(5))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. GitHubã«ãƒ—ãƒƒã‚·ãƒ¥\n",
                "\n",
                "Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒŸãƒƒãƒˆãƒ»ãƒ—ãƒƒã‚·ãƒ¥ã—ã¦ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã«ã™ã‚‹"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import subprocess\n",
                "import os\n",
                "\n",
                "os.chdir(PROJECT_ROOT)\n",
                "\n",
                "# Gitæ“ä½œ\n",
                "print(\"ğŸ“¤ GitHubã«ãƒ—ãƒƒã‚·ãƒ¥ä¸­...\")\n",
                "\n",
                "try:\n",
                "    # Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ \n",
                "    subprocess.run(['git', 'add', 'data/processed/races.parquet', 'data/processed/results.parquet'], check=True)\n",
                "    \n",
                "    # ã‚³ãƒŸãƒƒãƒˆ\n",
                "    result = subprocess.run(\n",
                "        ['git', 'commit', '-m', 'Update race data parquet files'],\n",
                "        capture_output=True, text=True\n",
                "    )\n",
                "    if result.returncode == 0:\n",
                "        print(\"âœ… ã‚³ãƒŸãƒƒãƒˆå®Œäº†\")\n",
                "    elif 'nothing to commit' in result.stdout or 'nothing to commit' in result.stderr:\n",
                "        print(\"â„¹ï¸ å¤‰æ›´ãªã—ï¼ˆã‚³ãƒŸãƒƒãƒˆä¸è¦ï¼‰\")\n",
                "    else:\n",
                "        print(f\"ã‚³ãƒŸãƒƒãƒˆçµæœ: {result.stderr}\")\n",
                "    \n",
                "    # ãƒ—ãƒƒã‚·ãƒ¥\n",
                "    result = subprocess.run(['git', 'push'], capture_output=True, text=True)\n",
                "    if result.returncode == 0:\n",
                "        print(\"âœ… ãƒ—ãƒƒã‚·ãƒ¥å®Œäº†!\")\n",
                "        print(\"\\nğŸŒ ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½:\")\n",
                "        print(\"   https://raw.githubusercontent.com/iinumac/keiba_prediction/main/data/processed/races.parquet\")\n",
                "        print(\"   https://raw.githubusercontent.com/iinumac/keiba_prediction/main/data/processed/results.parquet\")\n",
                "    else:\n",
                "        print(f\"ãƒ—ãƒƒã‚·ãƒ¥çµæœ: {result.stderr}\")\n",
                "        \n",
                "except Exception as e:\n",
                "    print(f\"âŒ ã‚¨ãƒ©ãƒ¼: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ç¢ºèª\n",
                "\n",
                "```python\n",
                "import pandas as pd\n",
                "\n",
                "BASE = \"https://raw.githubusercontent.com/iinumac/keiba_prediction/main/data/processed\"\n",
                "races_df = pd.read_parquet(f\"{BASE}/races.parquet\")\n",
                "results_df = pd.read_parquet(f\"{BASE}/results.parquet\")\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}