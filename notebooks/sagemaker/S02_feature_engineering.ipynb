{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S02: ãƒ‡ãƒ¼ã‚¿å¤‰æ›ï¼ˆHTML â†’ Parquetï¼‰\n",
    "\n",
    "HTMLã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦Parquetå½¢å¼ã§ä¿å­˜ã—ã€GitHubã«ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹ã“ã¨ã§ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‹ã‚‰å‚ç…§å¯èƒ½ã«ã™ã‚‹\n",
    "\n",
    "**å®Ÿè¡Œç’°å¢ƒ**: Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. ç’°å¢ƒè¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ\n",
    "PROJECT_ROOT = Path('../../')\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹\n",
    "HTML_DIR = PROJECT_ROOT / 'data' / 'raceHTML'\n",
    "PROCESSED_DIR = PROJECT_ROOT / 'data' / 'processed'\n",
    "\n",
    "# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹\n",
    "RACES_PARQUET = PROCESSED_DIR / 'races.parquet'\n",
    "RESULTS_PARQUET = PROCESSED_DIR / 'results.parquet'\n",
    "\n",
    "# GitHub RAW URLï¼ˆãƒ—ãƒƒã‚·ãƒ¥å¾Œã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ï¼‰\n",
    "GITHUB_BASE = \"https://raw.githubusercontent.com/iinumac/keiba_prediction/main/data/processed\"\n",
    "\n",
    "print(f\"HTML_DIR: {HTML_DIR.resolve()}\")\n",
    "print(f\"RACES_PARQUET: {RACES_PARQUET}\")\n",
    "print(f\"RESULTS_PARQUET: {RESULTS_PARQUET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "from scraper.parser import parse_multiple_html_full, classify_race_level\n",
    "\n",
    "print(\"âœ… ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. å…¨HTMLã‚’ãƒ‘ãƒ¼ã‚¹ â†’ Parquetä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_callback(processed, total, skipped=0):\n",
    "    pct = processed / total * 100 if total > 0 else 0\n",
    "    print(f\"\\ré€²æ—: {processed:,}/{total:,} ({pct:.1f}%)\", end='')\n",
    "\n",
    "print(\"ğŸ“Š HTMLãƒ‘ãƒ¼ã‚¹ã‚’é–‹å§‹...\")\n",
    "print(f\"å¯¾è±¡: {HTML_DIR}\")\n",
    "\n",
    "race_list, horse_list = parse_multiple_html_full(\n",
    "    HTML_DIR,\n",
    "    years=None,\n",
    "    progress_callback=progress_callback\n",
    ")\n",
    "\n",
    "print(f\"\\n\\nâœ… ãƒ‘ãƒ¼ã‚¹å®Œäº†\")\n",
    "print(f\"   ãƒ¬ãƒ¼ã‚¹æ•°: {len(race_list):,}\")\n",
    "print(f\"   å‡ºèµ°é¦¬ãƒ‡ãƒ¼ã‚¿æ•°: {len(horse_list):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameã«å¤‰æ›\n",
    "races_df = pd.DataFrame(race_list)\n",
    "results_df = pd.DataFrame(horse_list)\n",
    "\n",
    "print(f\"races_df: {races_df.shape}\")\n",
    "print(f\"results_df: {results_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parquetå½¢å¼ã§ä¿å­˜\n",
    "races_df.to_parquet(RACES_PARQUET, index=False, compression='snappy')\n",
    "results_df.to_parquet(RESULTS_PARQUET, index=False, compression='snappy')\n",
    "\n",
    "print(\"âœ… Parquetä¿å­˜å®Œäº†\")\n",
    "print(f\"   races.parquet: {RACES_PARQUET.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "print(f\"   results.parquet: {RESULTS_PARQUET.stat().st_size / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ãƒ‡ãƒ¼ã‚¿ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµ±è¨ˆ\n",
    "print(\"=== ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ ===\")\n",
    "print(f\"ãƒ¬ãƒ¼ã‚¹æ•°: {len(races_df):,}\")\n",
    "print(f\"å‡ºèµ°é¦¬ãƒ‡ãƒ¼ã‚¿æ•°: {len(results_df):,}\")\n",
    "\n",
    "if 'year' in races_df.columns:\n",
    "    print(\"\\n=== å¹´åˆ¥ãƒ¬ãƒ¼ã‚¹æ•° ===\")\n",
    "    print(races_df.groupby('year').size().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ\n",
    "if 'race_level' in races_df.columns:\n",
    "    print(\"=== ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ ===\")\n",
    "    print(races_df['race_level'].value_counts().sort_index().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º\n",
    "print(\"=== ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ ã‚µãƒ³ãƒ—ãƒ« ===\")\n",
    "display(races_df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== å‡ºèµ°é¦¬ãƒ‡ãƒ¼ã‚¿ ã‚µãƒ³ãƒ—ãƒ« ===\")\n",
    "display(results_df.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. GitHubã«ãƒ—ãƒƒã‚·ãƒ¥\n",
    "\n",
    "Parquetãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå¾Œã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ãƒ—ãƒƒã‚·ãƒ¥:\n",
    "\n",
    "```bash\n",
    "git add data/processed/*.parquet\n",
    "git commit -m \"Update race data parquet files\"\n",
    "git push\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gitã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "import subprocess\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "# Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ãƒ»ã‚³ãƒŸãƒƒãƒˆãƒ»ãƒ—ãƒƒã‚·ãƒ¥\n",
    "# subprocess.run(['git', 'add', 'data/processed/*.parquet'], check=True)\n",
    "# subprocess.run(['git', 'commit', '-m', 'Update race data parquet files'], check=True)\n",
    "# subprocess.run(['git', 'push'], check=True)\n",
    "\n",
    "print(\"âš ï¸ æ‰‹å‹•ã§git pushã—ã¦ãã ã•ã„ï¼ˆä¸Šã®ã‚³ãƒãƒ³ãƒ‰ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã—ã¦å®Ÿè¡Œã‚‚å¯èƒ½ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã®èª­ã¿è¾¼ã¿æ–¹æ³•\n",
    "\n",
    "GitHubã«ãƒ—ãƒƒã‚·ãƒ¥å¾Œã€ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã§èª­ã¿è¾¼ã¿å¯èƒ½:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# GitHub RAW URLã‹ã‚‰ç›´æ¥èª­ã¿è¾¼ã¿\n",
    "GITHUB_BASE = \"https://raw.githubusercontent.com/iinumac/keiba_prediction/main/data/processed\"\n",
    "\n",
    "races_df = pd.read_parquet(f\"{GITHUB_BASE}/races.parquet\")\n",
    "results_df = pd.read_parquet(f\"{GITHUB_BASE}/results.parquet\")\n",
    "\n",
    "# ç‰¹å®šã®é¦¬ã‚’æ¤œç´¢\n",
    "horse_id = \"2022110077\"\n",
    "horse_results = results_df[results_df['horse_id'] == horse_id]\n",
    "print(horse_results)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å®šã®é¦¬ã‚’æ¤œç´¢ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«\n",
    "horse_id = \"2022110077\"  # ã‚¤ãƒªãƒ•ã‚£\n",
    "horse_results = results_df[results_df['horse_id'] == horse_id]\n",
    "\n",
    "print(f\"=== é¦¬ID: {horse_id} ã®æˆç¸¾ ===\")\n",
    "print(f\"å‡ºèµ°å›æ•°: {len(horse_results)}\")\n",
    "display(horse_results[['race_date', 'venue_name', 'distance', 'surface', 'finish_position', 'popularity', 'odds', 'prize_money']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
