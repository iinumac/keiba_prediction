{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# L01: ç«¶é¦¬äºˆæƒ³ãƒ¢ãƒ‡ãƒ«å­¦ç¿’\n",
                "\n",
                "2ç¨®é¡ã®LightGBMãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ãƒ»æ¯”è¼ƒï¼š\n",
                "1. **ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«**: ç´”ç²‹ãªäºˆæ¸¬èƒ½åŠ›ï¼ˆãƒ¬ãƒ¼ã‚¹å‰æƒ…å ±ã®ã¿ï¼‰\n",
                "2. **ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«**: é€Ÿå ±ã‚ªãƒƒã‚ºã‚’å«ã‚€ï¼ˆç©´é¦¬ç™ºè¦‹ç”¨ï¼‰\n",
                "\n",
                "**å®Ÿè¡Œç’°å¢ƒ**: ãƒ­ãƒ¼ã‚«ãƒ«ï¼ˆM4 MacBook Airï¼‰"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. ç’°å¢ƒè¨­å®š"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "PROJECT_ROOT = Path('../../')\n",
                "sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
                "\n",
                "RACES_PARQUET = PROJECT_ROOT / 'data' / 'processed' / 'races.parquet'\n",
                "RESULTS_PARQUET = PROJECT_ROOT / 'data' / 'processed' / 'results.parquet'\n",
                "MODEL_DIR = PROJECT_ROOT / 'models'\n",
                "MODEL_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "print(f\"ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹: {RACES_PARQUET}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "races_df = pd.read_parquet(RACES_PARQUET)\n",
                "results_df = pd.read_parquet(RESULTS_PARQUET)\n",
                "\n",
                "print(f\"ãƒ¬ãƒ¼ã‚¹æ•°: {len(races_df):,}\")\n",
                "print(f\"å‡ºèµ°é¦¬ãƒ‡ãƒ¼ã‚¿æ•°: {len(results_df):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²\n",
                "\n",
                "- **Train**: 2010ã€œ2024å¹´\n",
                "- **Test**: 2025å¹´ã€œ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_df['race_date'] = pd.to_datetime(results_df['race_date'])\n",
                "results_df['year'] = results_df['race_date'].dt.year\n",
                "\n",
                "TRAIN_END_YEAR = 2024\n",
                "\n",
                "train_df = results_df[results_df['year'] <= TRAIN_END_YEAR].copy()\n",
                "test_df = results_df[results_df['year'] > TRAIN_END_YEAR].copy()\n",
                "\n",
                "print(f\"Train: {len(train_df):,} ({train_df['year'].min()}ã€œ{train_df['year'].max()})\")\n",
                "print(f\"Test: {len(test_df):,} ({test_df['year'].min()}ã€œ{test_df['year'].max()})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_historical_features(df, history_df):\n",
                "    \"\"\"å„å‡ºèµ°é¦¬ã®éå»æˆç¸¾ã‹ã‚‰ç‰¹å¾´é‡ã‚’è¨ˆç®—\"\"\"\n",
                "    history_df = history_df.sort_values('race_date')\n",
                "    \n",
                "    # é¦¬ã”ã¨ã®éå»æˆç¸¾\n",
                "    horse_stats = history_df.groupby('horse_id').agg({\n",
                "        'finish_position': ['count', 'mean'],\n",
                "        'race_id': 'count'\n",
                "    }).reset_index()\n",
                "    horse_stats.columns = ['horse_id', 'horse_race_count', 'horse_avg_finish', 'horse_total_races']\n",
                "    \n",
                "    win_stats = history_df.groupby('horse_id').apply(\n",
                "        lambda x: pd.Series({\n",
                "            'horse_win_rate': (x['finish_position'] == 1).sum() / len(x) if len(x) > 0 else 0,\n",
                "            'horse_place_rate': (x['finish_position'] <= 3).sum() / len(x) if len(x) > 0 else 0,\n",
                "        })\n",
                "    ).reset_index()\n",
                "    horse_stats = horse_stats.merge(win_stats, on='horse_id', how='left')\n",
                "    \n",
                "    # é¨æ‰‹ã®æˆç¸¾\n",
                "    jockey_stats = history_df.groupby('jockey_id').apply(\n",
                "        lambda x: pd.Series({\n",
                "            'jockey_race_count': len(x),\n",
                "            'jockey_win_rate': (x['finish_position'] == 1).sum() / len(x) if len(x) > 0 else 0,\n",
                "            'jockey_place_rate': (x['finish_position'] <= 3).sum() / len(x) if len(x) > 0 else 0,\n",
                "        })\n",
                "    ).reset_index()\n",
                "    \n",
                "    # èª¿æ•™å¸«ã®æˆç¸¾\n",
                "    trainer_stats = history_df.groupby('trainer_id').apply(\n",
                "        lambda x: pd.Series({\n",
                "            'trainer_race_count': len(x),\n",
                "            'trainer_win_rate': (x['finish_position'] == 1).sum() / len(x) if len(x) > 0 else 0,\n",
                "            'trainer_place_rate': (x['finish_position'] <= 3).sum() / len(x) if len(x) > 0 else 0,\n",
                "        })\n",
                "    ).reset_index()\n",
                "    \n",
                "    result = df.merge(horse_stats, on='horse_id', how='left')\n",
                "    result = result.merge(jockey_stats, on='jockey_id', how='left')\n",
                "    result = result.merge(trainer_stats, on='trainer_id', how='left')\n",
                "    \n",
                "    return result\n",
                "\n",
                "print(\"ç‰¹å¾´é‡è¨ˆç®—é–¢æ•°ã‚’å®šç¾©\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...\")\n",
                "\n",
                "all_history = results_df[results_df['year'] <= TRAIN_END_YEAR].copy()\n",
                "\n",
                "train_features = calculate_historical_features(train_df, all_history)\n",
                "test_features = calculate_historical_features(test_df, all_history)\n",
                "\n",
                "print(f\"Train features: {train_features.shape}\")\n",
                "print(f\"Test features: {test_features.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def add_features(df):\n",
                "    df = df.copy()\n",
                "    df['surface_encoded'] = df['surface'].map({'èŠ': 0, 'ãƒ€ãƒ¼ãƒˆ': 1}).fillna(-1)\n",
                "    df['target'] = (df['finish_position'] <= 3).astype(int)\n",
                "    return df\n",
                "\n",
                "train_features = add_features(train_features)\n",
                "test_features = add_features(test_features)\n",
                "\n",
                "print(\"ç‰¹å¾´é‡è¿½åŠ å®Œäº†\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. ãƒ¢ãƒ‡ãƒ«å®šç¾©\n",
                "\n",
                "### ç‰¹å¾´é‡ã®åˆ†é¡\n",
                "- **ãƒ¬ãƒ¼ã‚¹å‰æƒ…å ±**: distance, surface, level_score, horse_number, gate_number, impost, éå»æˆç¸¾\n",
                "- **ãƒ¬ãƒ¼ã‚¹ç›´å‰æƒ…å ±**: popularityï¼ˆäººæ°—ï¼‰, oddsï¼ˆã‚ªãƒƒã‚ºï¼‰"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import lightgbm as lgb\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import roc_auc_score, accuracy_score\n",
                "\n",
                "# ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«ï¼ˆç´”ç²‹äºˆæ¸¬ï¼‰\n",
                "FEATURE_COLS_NO_ODDS = [\n",
                "    # ãƒ¬ãƒ¼ã‚¹æƒ…å ±ï¼ˆãƒ¬ãƒ¼ã‚¹å‰ã«ç¢ºå®šï¼‰\n",
                "    'distance', 'surface_encoded', 'level_score',\n",
                "    'horse_number', 'gate_number', 'impost',\n",
                "    # é¦¬ã®éå»æˆç¸¾\n",
                "    'horse_race_count', 'horse_avg_finish',\n",
                "    'horse_win_rate', 'horse_place_rate',\n",
                "    # é¨æ‰‹ã®æˆç¸¾\n",
                "    'jockey_race_count', 'jockey_win_rate', 'jockey_place_rate',\n",
                "    # èª¿æ•™å¸«ã®æˆç¸¾\n",
                "    'trainer_race_count', 'trainer_win_rate', 'trainer_place_rate',\n",
                "]\n",
                "\n",
                "# ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«ï¼ˆé€Ÿå ±ã‚ªãƒƒã‚ºè¾¼ã¿ï¼‰\n",
                "FEATURE_COLS_WITH_ODDS = FEATURE_COLS_NO_ODDS + ['popularity', 'odds']\n",
                "\n",
                "print(\"ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«ç‰¹å¾´é‡:\", len(FEATURE_COLS_NO_ODDS))\n",
                "print(\"ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«ç‰¹å¾´é‡:\", len(FEATURE_COLS_WITH_ODDS))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ãƒ‡ãƒ¼ã‚¿æº–å‚™\n",
                "train_clean = train_features.dropna(subset=['target'] + FEATURE_COLS_WITH_ODDS)\n",
                "test_clean = test_features.dropna(subset=['target'] + FEATURE_COLS_WITH_ODDS)\n",
                "\n",
                "print(f\"Train (clean): {len(train_clean):,}\")\n",
                "print(f\"Test (clean): {len(test_clean):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»è©•ä¾¡"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_and_evaluate(train_data, test_data, feature_cols, model_name):\n",
                "    \"\"\"ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨è©•ä¾¡\"\"\"\n",
                "    print(f\"\\n{'='*50}\")\n",
                "    print(f\"ğŸ¯ {model_name}\")\n",
                "    print(f\"{'='*50}\")\n",
                "    \n",
                "    X_train = train_data[feature_cols]\n",
                "    y_train = train_data['target']\n",
                "    X_test = test_data[feature_cols]\n",
                "    y_test = test_data['target']\n",
                "    \n",
                "    # Validation split\n",
                "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
                "        X_train, y_train, test_size=0.2, random_state=42\n",
                "    )\n",
                "    \n",
                "    params = {\n",
                "        'objective': 'binary',\n",
                "        'metric': 'auc',\n",
                "        'learning_rate': 0.05,\n",
                "        'num_leaves': 31,\n",
                "        'feature_fraction': 0.8,\n",
                "        'bagging_fraction': 0.8,\n",
                "        'bagging_freq': 5,\n",
                "        'verbose': -1,\n",
                "        'random_state': 42,\n",
                "    }\n",
                "    \n",
                "    train_ds = lgb.Dataset(X_tr, label=y_tr)\n",
                "    val_ds = lgb.Dataset(X_val, label=y_val, reference=train_ds)\n",
                "    \n",
                "    model = lgb.train(\n",
                "        params,\n",
                "        train_ds,\n",
                "        num_boost_round=500,\n",
                "        valid_sets=[train_ds, val_ds],\n",
                "        valid_names=['train', 'valid'],\n",
                "        callbacks=[\n",
                "            lgb.early_stopping(stopping_rounds=50),\n",
                "            lgb.log_evaluation(period=0)  # é™éŸ³\n",
                "        ]\n",
                "    )\n",
                "    \n",
                "    # äºˆæ¸¬\n",
                "    y_pred_proba = model.predict(X_test)\n",
                "    \n",
                "    # è©•ä¾¡\n",
                "    auc = roc_auc_score(y_test, y_pred_proba)\n",
                "    print(f\"\\nğŸ“Š Test AUC: {auc:.4f}\")\n",
                "    \n",
                "    # ãƒ¬ãƒ¼ã‚¹ã”ã¨ã®çš„ä¸­ç‡\n",
                "    test_with_pred = test_data.copy()\n",
                "    test_with_pred['pred_proba'] = y_pred_proba\n",
                "    \n",
                "    def calc_hit_rate(group, top_n=3):\n",
                "        top_preds = group.nlargest(top_n, 'pred_proba')\n",
                "        return (top_preds['finish_position'] <= 3).any()\n",
                "    \n",
                "    race_hit = test_with_pred.groupby('race_id').apply(calc_hit_rate)\n",
                "    hit_rate = race_hit.mean()\n",
                "    print(f\"ğŸ¯ ä¸Šä½3é ­äºˆæ¸¬ã®çš„ä¸­ç‡: {hit_rate:.1%}\")\n",
                "    \n",
                "    # å›åç‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\n",
                "    def simulate_returns(group):\n",
                "        top = group.nlargest(1, 'pred_proba').iloc[0]\n",
                "        return top['odds'] * 100 if top['finish_position'] == 1 else 0\n",
                "    \n",
                "    returns = test_with_pred.groupby('race_id').apply(simulate_returns)\n",
                "    total_bet = len(returns) * 100\n",
                "    total_return = returns.sum()\n",
                "    return_rate = total_return / total_bet * 100\n",
                "    print(f\"ğŸ’° å˜å‹å›åç‡: {return_rate:.1f}%\")\n",
                "    \n",
                "    # ç‰¹å¾´é‡é‡è¦åº¦\n",
                "    importance = pd.DataFrame({\n",
                "        'feature': feature_cols,\n",
                "        'importance': model.feature_importance()\n",
                "    }).sort_values('importance', ascending=False)\n",
                "    \n",
                "    return {\n",
                "        'model': model,\n",
                "        'auc': auc,\n",
                "        'hit_rate': hit_rate,\n",
                "        'return_rate': return_rate,\n",
                "        'importance': importance,\n",
                "        'predictions': test_with_pred\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«\n",
                "result_no_odds = train_and_evaluate(\n",
                "    train_clean, test_clean,\n",
                "    FEATURE_COLS_NO_ODDS,\n",
                "    \"ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«ï¼ˆç´”ç²‹äºˆæ¸¬ï¼‰\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«\n",
                "result_with_odds = train_and_evaluate(\n",
                "    train_clean, test_clean,\n",
                "    FEATURE_COLS_WITH_ODDS,\n",
                "    \"ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«ï¼ˆé€Ÿå ±ã‚ªãƒƒã‚ºè¾¼ã¿ï¼‰\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"ğŸ“Š ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚µãƒãƒªãƒ¼\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "comparison = pd.DataFrame({\n",
                "    'æŒ‡æ¨™': ['AUC', 'çš„ä¸­ç‡ï¼ˆä¸Šä½3é ­â†’3ç€å†…ï¼‰', 'å˜å‹å›åç‡'],\n",
                "    'ã‚ªãƒƒã‚ºãªã—': [\n",
                "        f\"{result_no_odds['auc']:.4f}\",\n",
                "        f\"{result_no_odds['hit_rate']:.1%}\",\n",
                "        f\"{result_no_odds['return_rate']:.1f}%\"\n",
                "    ],\n",
                "    'ã‚ªãƒƒã‚ºã‚ã‚Š': [\n",
                "        f\"{result_with_odds['auc']:.4f}\",\n",
                "        f\"{result_with_odds['hit_rate']:.1%}\",\n",
                "        f\"{result_with_odds['return_rate']:.1f}%\"\n",
                "    ]\n",
                "})\n",
                "\n",
                "print(comparison.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ç‰¹å¾´é‡é‡è¦åº¦ã®æ¯”è¼ƒ\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "\n",
                "for ax, (name, result) in zip(axes, [\n",
                "    ('ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«', result_no_odds),\n",
                "    ('ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«', result_with_odds)\n",
                "]):\n",
                "    imp = result['importance'].head(10)\n",
                "    ax.barh(imp['feature'], imp['importance'])\n",
                "    ax.set_xlabel('Importance')\n",
                "    ax.set_title(f'{name}\\nTop 10 Features')\n",
                "    ax.invert_yaxis()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. ãƒ¢ãƒ‡ãƒ«ä¿å­˜"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "\n",
                "# ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«\n",
                "with open(MODEL_DIR / 'model_no_odds.pkl', 'wb') as f:\n",
                "    pickle.dump(result_no_odds['model'], f)\n",
                "\n",
                "# ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«\n",
                "with open(MODEL_DIR / 'model_with_odds.pkl', 'wb') as f:\n",
                "    pickle.dump(result_with_odds['model'], f)\n",
                "\n",
                "# è¨­å®š\n",
                "config = {\n",
                "    'feature_cols_no_odds': FEATURE_COLS_NO_ODDS,\n",
                "    'feature_cols_with_odds': FEATURE_COLS_WITH_ODDS,\n",
                "    'train_end_year': TRAIN_END_YEAR,\n",
                "}\n",
                "\n",
                "with open(MODEL_DIR / 'model_config.pkl', 'wb') as f:\n",
                "    pickle.dump(config, f)\n",
                "\n",
                "print(\"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†\")\n",
                "print(f\"  - {MODEL_DIR / 'model_no_odds.pkl'}\")\n",
                "print(f\"  - {MODEL_DIR / 'model_with_odds.pkl'}\")\n",
                "print(f\"  - {MODEL_DIR / 'model_config.pkl'}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}