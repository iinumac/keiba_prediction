{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# L01: ç«¶é¦¬äºˆæƒ³ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢ç‰ˆï¼‰\n",
                "\n",
                "## ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ\n",
                "- æ™‚ç³»åˆ—ã‚’å³å¯†ã«å®ˆã‚‹: å„ãƒ¬ãƒ¼ã‚¹æ™‚ç‚¹ã§ã®ã€Œéå»ã®ã¿ã€ã®ãƒ‡ãƒ¼ã‚¿ã§ç‰¹å¾´é‡è¨ˆç®—\n",
                "- å‰èµ°æƒ…å ±ã‚’ãƒ¡ã‚¤ãƒ³ã«ä½¿ç”¨ï¼ˆshift ã§å–å¾—ï¼‰\n",
                "\n",
                "**å®Ÿè¡Œç’°å¢ƒ**: ãƒ­ãƒ¼ã‚«ãƒ«ï¼ˆM4 MacBook Airï¼‰"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. ç’°å¢ƒè¨­å®š"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "PROJECT_ROOT = Path('../../')\n",
                "sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
                "\n",
                "RESULTS_PARQUET = PROJECT_ROOT / 'data' / 'processed' / 'results.parquet'\n",
                "MODEL_DIR = PROJECT_ROOT / 'models'\n",
                "MODEL_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "print(f\"ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹: {RESULTS_PARQUET}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_df = pd.read_parquet(RESULTS_PARQUET)\n",
                "print(f\"å‡ºèµ°é¦¬ãƒ‡ãƒ¼ã‚¿æ•°: {len(results_df):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. å‰å‡¦ç†ãƒ»å‰èµ°æƒ…å ±è¿½åŠ "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_df['race_date'] = pd.to_datetime(results_df['race_date'])\n",
                "results_df['year'] = results_df['race_date'].dt.year\n",
                "\n",
                "# å®Œèµ°é¦¬ã®ã¿\n",
                "results_df = results_df[results_df['is_finished'] == True].copy()\n",
                "\n",
                "# NaN IDã‚’åŸ‹ã‚ã‚‹ï¼ˆgroupbyã§ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œãªã„ã‚ˆã†ã«ï¼‰\n",
                "results_df['jockey_id'] = results_df['jockey_id'].fillna('unknown')\n",
                "results_df['trainer_id'] = results_df['trainer_id'].fillna('unknown')\n",
                "\n",
                "# é¦¬ã”ã¨ã«æ™‚ç³»åˆ—ã‚½ãƒ¼ãƒˆ\n",
                "results_df = results_df.sort_values(['horse_id', 'race_date']).reset_index(drop=True)\n",
                "\n",
                "print(f\"ãƒ‡ãƒ¼ã‚¿æ•°: {len(results_df):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# å‰èµ°æƒ…å ±ï¼ˆshift ã§å®‰å…¨ã«å–å¾—ï¼‰\n",
                "print(\"å‰èµ°æƒ…å ±ã‚’è¨ˆç®—ä¸­...\")\n",
                "results_df['prev_finish'] = results_df.groupby('horse_id')['finish_position'].shift(1)\n",
                "results_df['prev_last_3f'] = results_df.groupby('horse_id')['last_3f'].shift(1)\n",
                "results_df['prev_odds'] = results_df.groupby('horse_id')['odds'].shift(1)\n",
                "results_df['prev_race_date'] = results_df.groupby('horse_id')['race_date'].shift(1)\n",
                "results_df['days_since_last'] = (results_df['race_date'] - results_df['prev_race_date']).dt.days\n",
                "\n",
                "# 2èµ°å‰ã€3èµ°å‰\n",
                "results_df['prev2_finish'] = results_df.groupby('horse_id')['finish_position'].shift(2)\n",
                "results_df['prev3_finish'] = results_df.groupby('horse_id')['finish_position'].shift(3)\n",
                "results_df['prev2_last_3f'] = results_df.groupby('horse_id')['last_3f'].shift(2)\n",
                "results_df['prev3_last_3f'] = results_df.groupby('horse_id')['last_3f'].shift(3)\n",
                "\n",
                "# ç›´è¿‘3èµ°ã®å¹³å‡\n",
                "results_df['avg_finish_last3'] = results_df[['prev_finish', 'prev2_finish', 'prev3_finish']].mean(axis=1)\n",
                "results_df['avg_last3f_last3'] = results_df[['prev_last_3f', 'prev2_last_3f', 'prev3_last_3f']].mean(axis=1)\n",
                "\n",
                "# æ–°é¦¬ãƒ•ãƒ©ã‚°\n",
                "results_df['is_debut'] = results_df['prev_finish'].isna().astype(int)\n",
                "\n",
                "print(\"å®Œäº†\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# é¦¬ã®ç´¯ç©çµ±è¨ˆï¼ˆtransformã§åŒã˜é•·ã•ã‚’ä¿è¨¼ï¼‰\n",
                "print(\"é¦¬ã®ç´¯ç©çµ±è¨ˆã‚’è¨ˆç®—ä¸­...\")\n",
                "\n",
                "results_df['horse_cumulative_races'] = results_df.groupby('horse_id').cumcount()\n",
                "\n",
                "# å‹ã¡ãƒ•ãƒ©ã‚°ï¼ˆshift ã§éå»ã®ã¿ï¼‰\n",
                "results_df['_win'] = (results_df.groupby('horse_id')['finish_position'].shift(1) == 1).astype(int)\n",
                "results_df['_place'] = (results_df.groupby('horse_id')['finish_position'].shift(1) <= 3).astype(int)\n",
                "results_df['horse_cumulative_wins'] = results_df.groupby('horse_id')['_win'].cumsum()\n",
                "results_df['horse_cumulative_place'] = results_df.groupby('horse_id')['_place'].cumsum()\n",
                "\n",
                "# å‹ç‡ãƒ»è¤‡å‹ç‡\n",
                "results_df['horse_win_rate'] = results_df['horse_cumulative_wins'] / results_df['horse_cumulative_races'].replace(0, np.nan)\n",
                "results_df['horse_place_rate'] = results_df['horse_cumulative_place'] / results_df['horse_cumulative_races'].replace(0, np.nan)\n",
                "\n",
                "results_df.drop(columns=['_win', '_place'], inplace=True)\n",
                "print(\"å®Œäº†\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# é¨æ‰‹ãƒ»èª¿æ•™å¸«ã®ç´¯ç©æˆç¸¾\n",
                "print(\"é¨æ‰‹ãƒ»èª¿æ•™å¸«ã®ç´¯ç©æˆç¸¾ã‚’è¨ˆç®—ä¸­...\")\n",
                "\n",
                "# æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆï¼ˆé‡è¦ï¼‰\n",
                "results_df = results_df.sort_values('race_date').reset_index(drop=True)\n",
                "\n",
                "# é¨æ‰‹\n",
                "results_df['jockey_cumulative_races'] = results_df.groupby('jockey_id').cumcount()\n",
                "results_df['_jwin'] = (results_df.groupby('jockey_id')['finish_position'].shift(1) == 1).astype(int)\n",
                "results_df['_jplace'] = (results_df.groupby('jockey_id')['finish_position'].shift(1) <= 3).astype(int)\n",
                "results_df['jockey_cumulative_wins'] = results_df.groupby('jockey_id')['_jwin'].cumsum()\n",
                "results_df['jockey_cumulative_place'] = results_df.groupby('jockey_id')['_jplace'].cumsum()\n",
                "results_df['jockey_win_rate'] = results_df['jockey_cumulative_wins'] / results_df['jockey_cumulative_races'].replace(0, np.nan)\n",
                "results_df['jockey_place_rate'] = results_df['jockey_cumulative_place'] / results_df['jockey_cumulative_races'].replace(0, np.nan)\n",
                "results_df.drop(columns=['_jwin', '_jplace'], inplace=True)\n",
                "\n",
                "# èª¿æ•™å¸«\n",
                "results_df['trainer_cumulative_races'] = results_df.groupby('trainer_id').cumcount()\n",
                "results_df['_twin'] = (results_df.groupby('trainer_id')['finish_position'].shift(1) == 1).astype(int)\n",
                "results_df['_tplace'] = (results_df.groupby('trainer_id')['finish_position'].shift(1) <= 3).astype(int)\n",
                "results_df['trainer_cumulative_wins'] = results_df.groupby('trainer_id')['_twin'].cumsum()\n",
                "results_df['trainer_cumulative_place'] = results_df.groupby('trainer_id')['_tplace'].cumsum()\n",
                "results_df['trainer_win_rate'] = results_df['trainer_cumulative_wins'] / results_df['trainer_cumulative_races'].replace(0, np.nan)\n",
                "results_df['trainer_place_rate'] = results_df['trainer_cumulative_place'] / results_df['trainer_cumulative_races'].replace(0, np.nan)\n",
                "results_df.drop(columns=['_twin', '_tplace'], inplace=True)\n",
                "\n",
                "print(\"å®Œäº†\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "TRAIN_END_YEAR = 2024\n",
                "\n",
                "train_df = results_df[results_df['year'] <= TRAIN_END_YEAR].copy()\n",
                "test_df = results_df[results_df['year'] > TRAIN_END_YEAR].copy()\n",
                "\n",
                "train_df['surface_encoded'] = train_df['surface'].map({'èŠ': 0, 'ãƒ€ãƒ¼ãƒˆ': 1}).fillna(-1)\n",
                "test_df['surface_encoded'] = test_df['surface'].map({'èŠ': 0, 'ãƒ€ãƒ¼ãƒˆ': 1}).fillna(-1)\n",
                "train_df['target'] = (train_df['finish_position'] <= 3).astype(int)\n",
                "test_df['target'] = (test_df['finish_position'] <= 3).astype(int)\n",
                "\n",
                "print(f\"Train: {len(train_df):,}\")\n",
                "print(f\"Test: {len(test_df):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import lightgbm as lgb\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import roc_auc_score\n",
                "\n",
                "FEATURE_COLS_NO_ODDS = [\n",
                "    'distance', 'surface_encoded', 'level_score',\n",
                "    'horse_number', 'gate_number', 'impost',\n",
                "    'prev_finish', 'prev_last_3f', 'days_since_last', 'is_debut',\n",
                "    'prev2_finish', 'prev3_finish',\n",
                "    'avg_finish_last3', 'avg_last3f_last3',\n",
                "    'horse_cumulative_races', 'horse_win_rate', 'horse_place_rate',\n",
                "    'jockey_cumulative_races', 'jockey_win_rate', 'jockey_place_rate',\n",
                "    'trainer_cumulative_races', 'trainer_win_rate', 'trainer_place_rate',\n",
                "]\n",
                "\n",
                "FEATURE_COLS_WITH_ODDS = FEATURE_COLS_NO_ODDS + ['popularity', 'odds']\n",
                "\n",
                "print(f\"ã‚ªãƒƒã‚ºãªã—: {len(FEATURE_COLS_NO_ODDS)}å€‹\")\n",
                "print(f\"ã‚ªãƒƒã‚ºã‚ã‚Š: {len(FEATURE_COLS_WITH_ODDS)}å€‹\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for col in FEATURE_COLS_WITH_ODDS:\n",
                "    if col in train_df.columns:\n",
                "        train_df[col] = train_df[col].fillna(0)\n",
                "        test_df[col] = test_df[col].fillna(0)\n",
                "\n",
                "train_clean = train_df.dropna(subset=['target'])\n",
                "test_clean = test_df.dropna(subset=['target'])\n",
                "\n",
                "print(f\"Train: {len(train_clean):,}, Test: {len(test_clean):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_and_evaluate(train_data, test_data, feature_cols, model_name):\n",
                "    print(f\"\\n{'='*50}\")\n",
                "    print(f\"ğŸ¯ {model_name}\")\n",
                "    print(f\"{'='*50}\")\n",
                "    \n",
                "    X_train = train_data[feature_cols]\n",
                "    y_train = train_data['target']\n",
                "    X_test = test_data[feature_cols]\n",
                "    y_test = test_data['target']\n",
                "    \n",
                "    X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
                "    \n",
                "    params = {\n",
                "        'objective': 'binary',\n",
                "        'metric': 'auc',\n",
                "        'learning_rate': 0.05,\n",
                "        'num_leaves': 15,\n",
                "        'min_data_in_leaf': 100,\n",
                "        'feature_fraction': 0.7,\n",
                "        'bagging_fraction': 0.7,\n",
                "        'bagging_freq': 5,\n",
                "        'lambda_l1': 0.1,\n",
                "        'lambda_l2': 0.1,\n",
                "        'verbose': -1,\n",
                "        'random_state': 42,\n",
                "    }\n",
                "    \n",
                "    model = lgb.train(\n",
                "        params,\n",
                "        lgb.Dataset(X_tr, label=y_tr),\n",
                "        num_boost_round=1000,\n",
                "        valid_sets=[lgb.Dataset(X_tr, label=y_tr), lgb.Dataset(X_val, label=y_val)],\n",
                "        valid_names=['train', 'valid'],\n",
                "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
                "    )\n",
                "    \n",
                "    y_pred = model.predict(X_test)\n",
                "    auc = roc_auc_score(y_test, y_pred)\n",
                "    print(f\"\\nğŸ“Š Test AUC: {auc:.4f}\")\n",
                "    \n",
                "    test_with_pred = test_data.copy()\n",
                "    test_with_pred['pred_proba'] = y_pred\n",
                "    \n",
                "    # çš„ä¸­ç‡\n",
                "    race_hit = test_with_pred.groupby('race_id').apply(\n",
                "        lambda g: (g.nlargest(3, 'pred_proba')['finish_position'] <= 3).any()\n",
                "    )\n",
                "    print(f\"ğŸ¯ ä¸Šä½3é ­çš„ä¸­ç‡: {race_hit.mean():.1%}\")\n",
                "    \n",
                "    # å˜å‹å›åç‡\n",
                "    returns = test_with_pred.groupby('race_id').apply(\n",
                "        lambda g: g.nlargest(1, 'pred_proba').iloc[0]['odds'] * 100 \n",
                "                  if g.nlargest(1, 'pred_proba').iloc[0]['finish_position'] == 1 else 0\n",
                "    )\n",
                "    return_rate = returns.sum() / (len(returns) * 100) * 100\n",
                "    print(f\"ğŸ’° å˜å‹å›åç‡: {return_rate:.1f}%\")\n",
                "    \n",
                "    # ä¸‰é€£è¤‡\n",
                "    sanren = test_with_pred.groupby('race_id').apply(\n",
                "        lambda g: len(set(g.nsmallest(3, 'finish_position')['horse_id']) & \n",
                "                      set(g.nlargest(5, 'pred_proba')['horse_id'])) >= 3\n",
                "    )\n",
                "    print(f\"ğŸ‡ ä¸‰é€£è¤‡çš„ä¸­ç‡ï¼ˆ5é ­é¸æŠï¼‰: {sanren.mean():.1%}\")\n",
                "    \n",
                "    importance = pd.DataFrame({\n",
                "        'feature': feature_cols,\n",
                "        'importance': model.feature_importance()\n",
                "    }).sort_values('importance', ascending=False)\n",
                "    \n",
                "    return {'model': model, 'auc': auc, 'hit_rate': race_hit.mean(), \n",
                "            'return_rate': return_rate, 'sanren_rate': sanren.mean(), \n",
                "            'importance': importance, 'predictions': test_with_pred}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_no_odds = train_and_evaluate(train_clean, test_clean, FEATURE_COLS_NO_ODDS, \"ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_with_odds = train_and_evaluate(train_clean, test_clean, FEATURE_COLS_WITH_ODDS, \"ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. æ¯”è¼ƒãƒ»ä¿å­˜"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"ğŸ“Š ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "print(pd.DataFrame({\n",
                "    'æŒ‡æ¨™': ['AUC', 'ä¸Šä½3é ­çš„ä¸­ç‡', 'ä¸‰é€£è¤‡çš„ä¸­ç‡', 'å˜å‹å›åç‡'],\n",
                "    'ã‚ªãƒƒã‚ºãªã—': [f\"{result_no_odds['auc']:.4f}\", f\"{result_no_odds['hit_rate']:.1%}\", \n",
                "                   f\"{result_no_odds['sanren_rate']:.1%}\", f\"{result_no_odds['return_rate']:.1f}%\"],\n",
                "    'ã‚ªãƒƒã‚ºã‚ã‚Š': [f\"{result_with_odds['auc']:.4f}\", f\"{result_with_odds['hit_rate']:.1%}\",\n",
                "                   f\"{result_with_odds['sanren_rate']:.1%}\", f\"{result_with_odds['return_rate']:.1f}%\"]\n",
                "}).to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=== ç‰¹å¾´é‡é‡è¦åº¦ (ã‚ªãƒƒã‚ºãªã—) ===\")\n",
                "print(result_no_odds['importance'].to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "\n",
                "with open(MODEL_DIR / 'model_no_odds.pkl', 'wb') as f:\n",
                "    pickle.dump(result_no_odds['model'], f)\n",
                "with open(MODEL_DIR / 'model_with_odds.pkl', 'wb') as f:\n",
                "    pickle.dump(result_with_odds['model'], f)\n",
                "\n",
                "config = {\n",
                "    'feature_cols_no_odds': FEATURE_COLS_NO_ODDS,\n",
                "    'feature_cols_with_odds': FEATURE_COLS_WITH_ODDS,\n",
                "    'train_end_year': TRAIN_END_YEAR,\n",
                "}\n",
                "with open(MODEL_DIR / 'model_config.pkl', 'wb') as f:\n",
                "    pickle.dump(config, f)\n",
                "\n",
                "print(\"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}