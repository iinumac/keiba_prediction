{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# L01: ç«¶é¦¬äºˆæƒ³ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢ç‰ˆï¼‰\n",
                "\n",
                "## ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ\n",
                "- æ™‚ç³»åˆ—ã‚’å³å¯†ã«å®ˆã‚‹: å„ãƒ¬ãƒ¼ã‚¹æ™‚ç‚¹ã§ã®ã€Œéå»ã®ã¿ã€ã®ãƒ‡ãƒ¼ã‚¿ã§ç‰¹å¾´é‡è¨ˆç®—\n",
                "- å‰èµ°æƒ…å ±ã‚’ãƒ¡ã‚¤ãƒ³ã«ä½¿ç”¨ï¼ˆshift ã§å–å¾—æ¸ˆã¿ï¼‰\n",
                "\n",
                "**å®Ÿè¡Œç’°å¢ƒ**: ãƒ­ãƒ¼ã‚«ãƒ«ï¼ˆM4 MacBook Airï¼‰"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. ç’°å¢ƒè¨­å®š"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "PROJECT_ROOT = Path('../../')\n",
                "sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
                "\n",
                "RACES_PARQUET = PROJECT_ROOT / 'data' / 'processed' / 'races.parquet'\n",
                "RESULTS_PARQUET = PROJECT_ROOT / 'data' / 'processed' / 'results.parquet'\n",
                "MODEL_DIR = PROJECT_ROOT / 'models'\n",
                "MODEL_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "print(f\"ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹: {RESULTS_PARQUET}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_df = pd.read_parquet(RESULTS_PARQUET)\n",
                "print(f\"å‡ºèµ°é¦¬ãƒ‡ãƒ¼ã‚¿æ•°: {len(results_df):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. å‰å‡¦ç†ãƒ»å‰èµ°æƒ…å ±è¿½åŠ \n",
                "\n",
                "**ãƒã‚¤ãƒ³ãƒˆ**: `shift()` ã‚’ä½¿ã†ã¨ã€Œãã®é¦¬ã®éå»ã®ãƒ¬ãƒ¼ã‚¹ã€æƒ…å ±ã‚’å®‰å…¨ã«å–å¾—ã§ãã‚‹ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ãªã—ï¼‰"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_df['race_date'] = pd.to_datetime(results_df['race_date'])\n",
                "results_df['year'] = results_df['race_date'].dt.year\n",
                "\n",
                "# å®Œèµ°é¦¬ã®ã¿\n",
                "results_df = results_df[results_df['is_finished'] == True].copy()\n",
                "\n",
                "# é¦¬ã”ã¨ã«æ™‚ç³»åˆ—ã‚½ãƒ¼ãƒˆ\n",
                "results_df = results_df.sort_values(['horse_id', 'race_date']).reset_index(drop=True)\n",
                "\n",
                "# å‰èµ°æƒ…å ±ï¼ˆshift ã§å®‰å…¨ã«å–å¾—ï¼‰\n",
                "print(\"å‰èµ°æƒ…å ±ã‚’è¨ˆç®—ä¸­...\")\n",
                "results_df['prev_finish'] = results_df.groupby('horse_id')['finish_position'].shift(1)\n",
                "results_df['prev_last_3f'] = results_df.groupby('horse_id')['last_3f'].shift(1)\n",
                "results_df['prev_odds'] = results_df.groupby('horse_id')['odds'].shift(1)\n",
                "results_df['prev_popularity'] = results_df.groupby('horse_id')['popularity'].shift(1)\n",
                "results_df['prev_race_date'] = results_df.groupby('horse_id')['race_date'].shift(1)\n",
                "results_df['days_since_last'] = (results_df['race_date'] - results_df['prev_race_date']).dt.days\n",
                "\n",
                "# 2èµ°å‰ã€3èµ°å‰\n",
                "results_df['prev2_finish'] = results_df.groupby('horse_id')['finish_position'].shift(2)\n",
                "results_df['prev3_finish'] = results_df.groupby('horse_id')['finish_position'].shift(3)\n",
                "results_df['prev2_last_3f'] = results_df.groupby('horse_id')['last_3f'].shift(2)\n",
                "results_df['prev3_last_3f'] = results_df.groupby('horse_id')['last_3f'].shift(3)\n",
                "\n",
                "# ç›´è¿‘3èµ°ã®å¹³å‡ç€é †ã€å¹³å‡ä¸ŠãŒã‚Š3F\n",
                "results_df['avg_finish_last3'] = results_df[['prev_finish', 'prev2_finish', 'prev3_finish']].mean(axis=1)\n",
                "results_df['avg_last3f_last3'] = results_df[['prev_last_3f', 'prev2_last_3f', 'prev3_last_3f']].mean(axis=1)\n",
                "\n",
                "# æ–°é¦¬ãƒ•ãƒ©ã‚°\n",
                "results_df['is_debut'] = results_df['prev_finish'].isna().astype(int)\n",
                "\n",
                "# ç´¯ç©çµ±è¨ˆï¼ˆshift ã§å®‰å…¨ã«: expanding ã‚’ä½¿ç”¨ï¼‰\n",
                "print(\"ç´¯ç©çµ±è¨ˆã‚’è¨ˆç®—ä¸­ï¼ˆæ™‚ç³»åˆ—å³å®ˆï¼‰...\")\n",
                "results_df['horse_cumulative_races'] = results_df.groupby('horse_id').cumcount()  # ãã®æ™‚ç‚¹ã§ã®é€šç®—å‡ºèµ°æ•°\n",
                "results_df['horse_cumulative_wins'] = results_df.groupby('horse_id')['finish_position'].apply(\n",
                "    lambda x: (x.shift() == 1).cumsum()\n",
                ").values\n",
                "results_df['horse_cumulative_place'] = results_df.groupby('horse_id')['finish_position'].apply(\n",
                "    lambda x: (x.shift() <= 3).cumsum()\n",
                ").values\n",
                "\n",
                "# å‹ç‡ãƒ»è¤‡å‹ç‡ï¼ˆãã®æ™‚ç‚¹ã¾ã§ï¼‰\n",
                "results_df['horse_win_rate'] = results_df['horse_cumulative_wins'] / results_df['horse_cumulative_races'].replace(0, np.nan)\n",
                "results_df['horse_place_rate'] = results_df['horse_cumulative_place'] / results_df['horse_cumulative_races'].replace(0, np.nan)\n",
                "\n",
                "print(\"å‰å‡¦ç†å®Œäº†\")\n",
                "print(f\"ãƒ‡ãƒ¼ã‚¿æ•°: {len(results_df):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# é¨æ‰‹ãƒ»èª¿æ•™å¸«ã®ç´¯ç©æˆç¸¾ã‚‚åŒæ§˜ã«è¨ˆç®—\n",
                "print(\"é¨æ‰‹ãƒ»èª¿æ•™å¸«ã®ç´¯ç©æˆç¸¾ã‚’è¨ˆç®—ä¸­...\")\n",
                "\n",
                "# æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆ\n",
                "results_df = results_df.sort_values('race_date').reset_index(drop=True)\n",
                "\n",
                "# é¨æ‰‹ã®ç´¯ç©\n",
                "results_df['jockey_cumulative_races'] = results_df.groupby('jockey_id').cumcount()\n",
                "results_df['jockey_cumulative_wins'] = results_df.groupby('jockey_id')['finish_position'].apply(\n",
                "    lambda x: (x.shift() == 1).cumsum()\n",
                ").values\n",
                "results_df['jockey_cumulative_place'] = results_df.groupby('jockey_id')['finish_position'].apply(\n",
                "    lambda x: (x.shift() <= 3).cumsum()\n",
                ").values\n",
                "results_df['jockey_win_rate'] = results_df['jockey_cumulative_wins'] / results_df['jockey_cumulative_races'].replace(0, np.nan)\n",
                "results_df['jockey_place_rate'] = results_df['jockey_cumulative_place'] / results_df['jockey_cumulative_races'].replace(0, np.nan)\n",
                "\n",
                "# èª¿æ•™å¸«ã®ç´¯ç©\n",
                "results_df['trainer_cumulative_races'] = results_df.groupby('trainer_id').cumcount()\n",
                "results_df['trainer_cumulative_wins'] = results_df.groupby('trainer_id')['finish_position'].apply(\n",
                "    lambda x: (x.shift() == 1).cumsum()\n",
                ").values\n",
                "results_df['trainer_cumulative_place'] = results_df.groupby('trainer_id')['finish_position'].apply(\n",
                "    lambda x: (x.shift() <= 3).cumsum()\n",
                ").values\n",
                "results_df['trainer_win_rate'] = results_df['trainer_cumulative_wins'] / results_df['trainer_cumulative_races'].replace(0, np.nan)\n",
                "results_df['trainer_place_rate'] = results_df['trainer_cumulative_place'] / results_df['trainer_cumulative_races'].replace(0, np.nan)\n",
                "\n",
                "print(\"å®Œäº†\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²\n",
                "\n",
                "- **Train**: 2010ã€œ2024å¹´\n",
                "- **Test**: 2025å¹´ã€œ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "TRAIN_END_YEAR = 2024\n",
                "\n",
                "train_df = results_df[results_df['year'] <= TRAIN_END_YEAR].copy()\n",
                "test_df = results_df[results_df['year'] > TRAIN_END_YEAR].copy()\n",
                "\n",
                "# è¿½åŠ ç‰¹å¾´é‡\n",
                "train_df['surface_encoded'] = train_df['surface'].map({'èŠ': 0, 'ãƒ€ãƒ¼ãƒˆ': 1}).fillna(-1)\n",
                "test_df['surface_encoded'] = test_df['surface'].map({'èŠ': 0, 'ãƒ€ãƒ¼ãƒˆ': 1}).fillna(-1)\n",
                "train_df['target'] = (train_df['finish_position'] <= 3).astype(int)\n",
                "test_df['target'] = (test_df['finish_position'] <= 3).astype(int)\n",
                "\n",
                "print(f\"Train: {len(train_df):,} ({train_df['year'].min()}ã€œ{train_df['year'].max()})\")\n",
                "print(f\"Test: {len(test_df):,} ({test_df['year'].min()}ã€œ{test_df['year'].max()})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import lightgbm as lgb\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import roc_auc_score\n",
                "\n",
                "# ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«ï¼ˆç´”ç²‹äºˆæ¸¬ï¼‰\n",
                "FEATURE_COLS_NO_ODDS = [\n",
                "    # ãƒ¬ãƒ¼ã‚¹æƒ…å ±\n",
                "    'distance', 'surface_encoded', 'level_score',\n",
                "    'horse_number', 'gate_number', 'impost',\n",
                "    # å‰èµ°æƒ…å ±ï¼ˆshift ã§å–å¾— = ãƒªãƒ¼ã‚¯ãªã—ï¼‰\n",
                "    'prev_finish', 'prev_last_3f', 'days_since_last', 'is_debut',\n",
                "    'prev2_finish', 'prev3_finish',\n",
                "    'avg_finish_last3', 'avg_last3f_last3',\n",
                "    # ç´¯ç©çµ±è¨ˆï¼ˆcumsum + shift = ãƒªãƒ¼ã‚¯ãªã—ï¼‰\n",
                "    'horse_cumulative_races', 'horse_win_rate', 'horse_place_rate',\n",
                "    'jockey_cumulative_races', 'jockey_win_rate', 'jockey_place_rate',\n",
                "    'trainer_cumulative_races', 'trainer_win_rate', 'trainer_place_rate',\n",
                "]\n",
                "\n",
                "# ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«\n",
                "FEATURE_COLS_WITH_ODDS = FEATURE_COLS_NO_ODDS + ['popularity', 'odds']\n",
                "\n",
                "print(\"ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«ç‰¹å¾´é‡:\", len(FEATURE_COLS_NO_ODDS), \"å€‹\")\n",
                "print(\"ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«ç‰¹å¾´é‡:\", len(FEATURE_COLS_WITH_ODDS), \"å€‹\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# NaNåŸ‹ã‚\n",
                "for col in FEATURE_COLS_WITH_ODDS:\n",
                "    if col in train_df.columns:\n",
                "        train_df[col] = train_df[col].fillna(0)\n",
                "        test_df[col] = test_df[col].fillna(0)\n",
                "\n",
                "train_clean = train_df.dropna(subset=['target'])\n",
                "test_clean = test_df.dropna(subset=['target'])\n",
                "\n",
                "print(f\"Train (clean): {len(train_clean):,}\")\n",
                "print(f\"Test (clean): {len(test_clean):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_and_evaluate(train_data, test_data, feature_cols, model_name):\n",
                "    print(f\"\\n{'='*50}\")\n",
                "    print(f\"ğŸ¯ {model_name}\")\n",
                "    print(f\"{'='*50}\")\n",
                "    \n",
                "    X_train = train_data[feature_cols]\n",
                "    y_train = train_data['target']\n",
                "    X_test = test_data[feature_cols]\n",
                "    y_test = test_data['target']\n",
                "    \n",
                "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
                "        X_train, y_train, test_size=0.2, random_state=42\n",
                "    )\n",
                "    \n",
                "    params = {\n",
                "        'objective': 'binary',\n",
                "        'metric': 'auc',\n",
                "        'learning_rate': 0.05,\n",
                "        'num_leaves': 15,  # éå­¦ç¿’é˜²æ­¢ã®ãŸã‚æ¸›ã‚‰ã™\n",
                "        'min_data_in_leaf': 100,  # éå­¦ç¿’é˜²æ­¢\n",
                "        'feature_fraction': 0.7,\n",
                "        'bagging_fraction': 0.7,\n",
                "        'bagging_freq': 5,\n",
                "        'lambda_l1': 0.1,\n",
                "        'lambda_l2': 0.1,\n",
                "        'verbose': -1,\n",
                "        'random_state': 42,\n",
                "    }\n",
                "    \n",
                "    train_ds = lgb.Dataset(X_tr, label=y_tr)\n",
                "    val_ds = lgb.Dataset(X_val, label=y_val, reference=train_ds)\n",
                "    \n",
                "    model = lgb.train(\n",
                "        params,\n",
                "        train_ds,\n",
                "        num_boost_round=1000,\n",
                "        valid_sets=[train_ds, val_ds],\n",
                "        valid_names=['train', 'valid'],\n",
                "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
                "    )\n",
                "    \n",
                "    y_pred = model.predict(X_test)\n",
                "    auc = roc_auc_score(y_test, y_pred)\n",
                "    print(f\"\\nğŸ“Š Test AUC: {auc:.4f}\")\n",
                "    \n",
                "    test_with_pred = test_data.copy()\n",
                "    test_with_pred['pred_proba'] = y_pred\n",
                "    \n",
                "    # çš„ä¸­ç‡\n",
                "    def calc_hit(group, top_n=3):\n",
                "        top_preds = group.nlargest(top_n, 'pred_proba')\n",
                "        return (top_preds['finish_position'] <= 3).any()\n",
                "    \n",
                "    race_hit = test_with_pred.groupby('race_id').apply(calc_hit)\n",
                "    print(f\"ğŸ¯ ä¸Šä½3é ­äºˆæ¸¬ã®çš„ä¸­ç‡: {race_hit.mean():.1%}\")\n",
                "    \n",
                "    # å˜å‹å›åç‡\n",
                "    def sim_returns(group):\n",
                "        top = group.nlargest(1, 'pred_proba').iloc[0]\n",
                "        return top['odds'] * 100 if top['finish_position'] == 1 else 0\n",
                "    \n",
                "    returns = test_with_pred.groupby('race_id').apply(sim_returns)\n",
                "    return_rate = returns.sum() / (len(returns) * 100) * 100\n",
                "    print(f\"ğŸ’° å˜å‹å›åç‡: {return_rate:.1f}%\")\n",
                "    \n",
                "    # ä¸‰é€£è¤‡\n",
                "    def calc_sanren(group):\n",
                "        top5 = group.nlargest(5, 'pred_proba')\n",
                "        actual_top3 = set(group.nsmallest(3, 'finish_position')['horse_id'])\n",
                "        pred_top5 = set(top5['horse_id'])\n",
                "        return len(actual_top3 & pred_top5) >= 3\n",
                "    \n",
                "    sanren = test_with_pred.groupby('race_id').apply(calc_sanren)\n",
                "    print(f\"ğŸ‡ ä¸‰é€£è¤‡çš„ä¸­ç‡ï¼ˆ5é ­é¸æŠï¼‰: {sanren.mean():.1%}\")\n",
                "    \n",
                "    importance = pd.DataFrame({\n",
                "        'feature': feature_cols,\n",
                "        'importance': model.feature_importance()\n",
                "    }).sort_values('importance', ascending=False)\n",
                "    \n",
                "    return {\n",
                "        'model': model,\n",
                "        'auc': auc,\n",
                "        'hit_rate': race_hit.mean(),\n",
                "        'return_rate': return_rate,\n",
                "        'sanren_rate': sanren.mean(),\n",
                "        'importance': importance,\n",
                "        'predictions': test_with_pred\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_no_odds = train_and_evaluate(\n",
                "    train_clean, test_clean,\n",
                "    FEATURE_COLS_NO_ODDS,\n",
                "    \"ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«ï¼ˆç´”ç²‹äºˆæ¸¬ï¼‰\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_with_odds = train_and_evaluate(\n",
                "    train_clean, test_clean,\n",
                "    FEATURE_COLS_WITH_ODDS,\n",
                "    \"ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«ï¼ˆé€Ÿå ±ã‚ªãƒƒã‚ºè¾¼ã¿ï¼‰\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"ğŸ“Š ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚µãƒãƒªãƒ¼\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "comparison = pd.DataFrame({\n",
                "    'æŒ‡æ¨™': ['AUC', 'ä¸Šä½3é ­çš„ä¸­ç‡', 'ä¸‰é€£è¤‡çš„ä¸­ç‡ï¼ˆ5é ­é¸æŠï¼‰', 'å˜å‹å›åç‡'],\n",
                "    'ã‚ªãƒƒã‚ºãªã—': [\n",
                "        f\"{result_no_odds['auc']:.4f}\",\n",
                "        f\"{result_no_odds['hit_rate']:.1%}\",\n",
                "        f\"{result_no_odds['sanren_rate']:.1%}\",\n",
                "        f\"{result_no_odds['return_rate']:.1f}%\"\n",
                "    ],\n",
                "    'ã‚ªãƒƒã‚ºã‚ã‚Š': [\n",
                "        f\"{result_with_odds['auc']:.4f}\",\n",
                "        f\"{result_with_odds['hit_rate']:.1%}\",\n",
                "        f\"{result_with_odds['sanren_rate']:.1%}\",\n",
                "        f\"{result_with_odds['return_rate']:.1f}%\"\n",
                "    ]\n",
                "})\n",
                "\n",
                "print(comparison.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "\n",
                "for ax, (name, result) in zip(axes, [\n",
                "    ('ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«', result_no_odds),\n",
                "    ('ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«', result_with_odds)\n",
                "]):\n",
                "    imp = result['importance'].head(12)\n",
                "    ax.barh(imp['feature'], imp['importance'])\n",
                "    ax.set_xlabel('Importance')\n",
                "    ax.set_title(f'{name}\\nTop 12 Features')\n",
                "    ax.invert_yaxis()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. ãƒ¢ãƒ‡ãƒ«ä¿å­˜"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "\n",
                "with open(MODEL_DIR / 'model_no_odds.pkl', 'wb') as f:\n",
                "    pickle.dump(result_no_odds['model'], f)\n",
                "\n",
                "with open(MODEL_DIR / 'model_with_odds.pkl', 'wb') as f:\n",
                "    pickle.dump(result_with_odds['model'], f)\n",
                "\n",
                "config = {\n",
                "    'feature_cols_no_odds': FEATURE_COLS_NO_ODDS,\n",
                "    'feature_cols_with_odds': FEATURE_COLS_WITH_ODDS,\n",
                "    'train_end_year': TRAIN_END_YEAR,\n",
                "}\n",
                "\n",
                "with open(MODEL_DIR / 'model_config.pkl', 'wb') as f:\n",
                "    pickle.dump(config, f)\n",
                "\n",
                "print(\"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}