{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# L01: ç«¶é¦¬äºˆæƒ³ãƒ¢ãƒ‡ãƒ«å­¦ç¿’\n",
                "\n",
                "## ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ\n",
                "1. **ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«**: ç´”ç²‹ãªäºˆæ¸¬ï¼ˆãƒ¬ãƒ¼ã‚¹å‰æƒ…å ±ã®ã¿ï¼‰\n",
                "2. **ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«**: é€Ÿå ±ã‚ªãƒƒã‚ºè¾¼ã¿\n",
                "\n",
                "**å®Ÿè¡Œç’°å¢ƒ**: ãƒ­ãƒ¼ã‚«ãƒ«ï¼ˆM4 MacBook Airï¼‰"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. ç’°å¢ƒè¨­å®š"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "PROJECT_ROOT = Path('../../')\n",
                "sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
                "\n",
                "RACES_PARQUET = PROJECT_ROOT / 'data' / 'processed' / 'races.parquet'\n",
                "RESULTS_PARQUET = PROJECT_ROOT / 'data' / 'processed' / 'results.parquet'\n",
                "MODEL_DIR = PROJECT_ROOT / 'models'\n",
                "MODEL_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "print(f\"ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹: {RACES_PARQUET}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "races_df = pd.read_parquet(RACES_PARQUET)\n",
                "results_df = pd.read_parquet(RESULTS_PARQUET)\n",
                "\n",
                "print(f\"ãƒ¬ãƒ¼ã‚¹æ•°: {len(races_df):,}\")\n",
                "print(f\"å‡ºèµ°é¦¬ãƒ‡ãƒ¼ã‚¿æ•°: {len(results_df):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ»åˆ†å‰²\n",
                "\n",
                "- **Train**: 2010ã€œ2024å¹´\n",
                "- **Test**: 2025å¹´ã€œ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_df['race_date'] = pd.to_datetime(results_df['race_date'])\n",
                "results_df['year'] = results_df['race_date'].dt.year\n",
                "\n",
                "# å®Œèµ°é¦¬ã®ã¿\n",
                "results_df = results_df[results_df['is_finished'] == True].copy()\n",
                "\n",
                "TRAIN_END_YEAR = 2024\n",
                "\n",
                "train_df = results_df[results_df['year'] <= TRAIN_END_YEAR].copy()\n",
                "test_df = results_df[results_df['year'] > TRAIN_END_YEAR].copy()\n",
                "\n",
                "print(f\"Train: {len(train_df):,} ({train_df['year'].min()}ã€œ{train_df['year'].max()})\")\n",
                "print(f\"Test: {len(test_df):,} ({test_df['year'].min()}ã€œ{test_df['year'].max()})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°\n",
                "\n",
                "### è¿½åŠ ç‰¹å¾´é‡\n",
                "- å‰èµ°ç€é †ã€å‰èµ°ä¸ŠãŒã‚Š3Fã€å‰èµ°ã‹ã‚‰ã®é–“éš”æ—¥æ•°\n",
                "- è·é›¢åˆ¥ãƒ»èŠãƒ€ãƒ¼ãƒˆåˆ¥ã®éå»æˆç¸¾"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def add_previous_race_features(df):\n",
                "    \"\"\"\n",
                "    å‰èµ°æƒ…å ±ã‚’ç‰¹å¾´é‡ã¨ã—ã¦è¿½åŠ \n",
                "    \"\"\"\n",
                "    df = df.sort_values(['horse_id', 'race_date']).copy()\n",
                "    \n",
                "    # å‰èµ°ã®æƒ…å ±ã‚’ã‚·ãƒ•ãƒˆã§å–å¾—ï¼ˆåŒã˜é¦¬ã®ã¿ï¼‰\n",
                "    df['prev_finish'] = df.groupby('horse_id')['finish_position'].shift(1)\n",
                "    df['prev_last_3f'] = df.groupby('horse_id')['last_3f'].shift(1)\n",
                "    df['prev_race_date'] = df.groupby('horse_id')['race_date'].shift(1)\n",
                "    \n",
                "    # å‰èµ°ã‹ã‚‰ã®é–“éš”æ—¥æ•°\n",
                "    df['days_since_last'] = (df['race_date'] - df['prev_race_date']).dt.days\n",
                "    \n",
                "    # å‰èµ°ãŒãªã‘ã‚Œã°æ–°é¦¬æ‰±ã„\n",
                "    df['is_debut'] = df['prev_finish'].isna().astype(int)\n",
                "    \n",
                "    return df\n",
                "\n",
                "print(\"å‰èµ°æƒ…å ±ã‚’è¿½åŠ ä¸­...\")\n",
                "results_with_prev = add_previous_race_features(results_df)\n",
                "print(f\"å®Œäº†: {len(results_with_prev):,} è¡Œ\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_historical_features(df, history_df):\n",
                "    \"\"\"å„å‡ºèµ°é¦¬ã®éå»æˆç¸¾ã‹ã‚‰ç‰¹å¾´é‡ã‚’è¨ˆç®—\"\"\"\n",
                "    history_df = history_df.sort_values('race_date')\n",
                "    \n",
                "    # é¦¬ã”ã¨ã®éå»æˆç¸¾\n",
                "    horse_stats = history_df.groupby('horse_id').agg({\n",
                "        'finish_position': ['count', 'mean'],\n",
                "    }).reset_index()\n",
                "    horse_stats.columns = ['horse_id', 'horse_race_count', 'horse_avg_finish']\n",
                "    \n",
                "    win_stats = history_df.groupby('horse_id').apply(\n",
                "        lambda x: pd.Series({\n",
                "            'horse_win_rate': (x['finish_position'] == 1).sum() / len(x) if len(x) > 0 else 0,\n",
                "            'horse_place_rate': (x['finish_position'] <= 3).sum() / len(x) if len(x) > 0 else 0,\n",
                "            'horse_avg_last_3f': x['last_3f'].mean(),\n",
                "        })\n",
                "    ).reset_index()\n",
                "    horse_stats = horse_stats.merge(win_stats, on='horse_id', how='left')\n",
                "    \n",
                "    # èŠãƒ»ãƒ€ãƒ¼ãƒˆåˆ¥æˆç¸¾\n",
                "    for surface_type in ['èŠ', 'ãƒ€ãƒ¼ãƒˆ']:\n",
                "        surface_hist = history_df[history_df['surface'] == surface_type]\n",
                "        surface_stats = surface_hist.groupby('horse_id').apply(\n",
                "            lambda x: pd.Series({\n",
                "                f'horse_{surface_type}_count': len(x),\n",
                "                f'horse_{surface_type}_place_rate': (x['finish_position'] <= 3).sum() / len(x) if len(x) > 0 else 0,\n",
                "            })\n",
                "        ).reset_index()\n",
                "        horse_stats = horse_stats.merge(surface_stats, on='horse_id', how='left')\n",
                "    \n",
                "    # é¨æ‰‹ã®æˆç¸¾\n",
                "    jockey_stats = history_df.groupby('jockey_id').apply(\n",
                "        lambda x: pd.Series({\n",
                "            'jockey_race_count': len(x),\n",
                "            'jockey_win_rate': (x['finish_position'] == 1).sum() / len(x) if len(x) > 0 else 0,\n",
                "            'jockey_place_rate': (x['finish_position'] <= 3).sum() / len(x) if len(x) > 0 else 0,\n",
                "        })\n",
                "    ).reset_index()\n",
                "    \n",
                "    # èª¿æ•™å¸«ã®æˆç¸¾\n",
                "    trainer_stats = history_df.groupby('trainer_id').apply(\n",
                "        lambda x: pd.Series({\n",
                "            'trainer_race_count': len(x),\n",
                "            'trainer_win_rate': (x['finish_position'] == 1).sum() / len(x) if len(x) > 0 else 0,\n",
                "            'trainer_place_rate': (x['finish_position'] <= 3).sum() / len(x) if len(x) > 0 else 0,\n",
                "        })\n",
                "    ).reset_index()\n",
                "    \n",
                "    result = df.merge(horse_stats, on='horse_id', how='left')\n",
                "    result = result.merge(jockey_stats, on='jockey_id', how='left')\n",
                "    result = result.merge(trainer_stats, on='trainer_id', how='left')\n",
                "    \n",
                "    return result\n",
                "\n",
                "print(\"ç‰¹å¾´é‡è¨ˆç®—é–¢æ•°ã‚’å®šç¾©\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"ç‰¹å¾´é‡ã‚’è¨ˆç®—ä¸­...\")\n",
                "\n",
                "# å‰èµ°æƒ…å ±ä»˜ããƒ‡ãƒ¼ã‚¿ã§åˆ†å‰²\n",
                "train_with_prev = results_with_prev[results_with_prev['year'] <= TRAIN_END_YEAR].copy()\n",
                "test_with_prev = results_with_prev[results_with_prev['year'] > TRAIN_END_YEAR].copy()\n",
                "\n",
                "all_history = results_with_prev[results_with_prev['year'] <= TRAIN_END_YEAR].copy()\n",
                "\n",
                "train_features = calculate_historical_features(train_with_prev, all_history)\n",
                "test_features = calculate_historical_features(test_with_prev, all_history)\n",
                "\n",
                "print(f\"Train features: {train_features.shape}\")\n",
                "print(f\"Test features: {test_features.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def add_final_features(df):\n",
                "    df = df.copy()\n",
                "    df['surface_encoded'] = df['surface'].map({'èŠ': 0, 'ãƒ€ãƒ¼ãƒˆ': 1}).fillna(-1)\n",
                "    df['target'] = (df['finish_position'] <= 3).astype(int)\n",
                "    \n",
                "    # ã‚³ãƒ¼ã‚¹é©æ€§ï¼ˆä»Šå›ã®ã‚³ãƒ¼ã‚¹ã§ã®è¤‡å‹ç‡ï¼‰\n",
                "    df['surface_match'] = np.where(\n",
                "        df['surface'] == 'èŠ',\n",
                "        df['horse_èŠ_place_rate'],\n",
                "        df['horse_ãƒ€ãƒ¼ãƒˆ_place_rate']\n",
                "    )\n",
                "    \n",
                "    return df\n",
                "\n",
                "train_features = add_final_features(train_features)\n",
                "test_features = add_final_features(test_features)\n",
                "\n",
                "print(\"ç‰¹å¾´é‡è¿½åŠ å®Œäº†\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. ãƒ¢ãƒ‡ãƒ«å®šç¾©"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import lightgbm as lgb\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import roc_auc_score\n",
                "\n",
                "# ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«ï¼ˆç´”ç²‹äºˆæ¸¬ï¼‰\n",
                "FEATURE_COLS_NO_ODDS = [\n",
                "    # ãƒ¬ãƒ¼ã‚¹æƒ…å ±\n",
                "    'distance', 'surface_encoded', 'level_score',\n",
                "    'horse_number', 'gate_number', 'impost',\n",
                "    # å‰èµ°æƒ…å ±\n",
                "    'prev_finish', 'prev_last_3f', 'days_since_last', 'is_debut',\n",
                "    # é¦¬ã®éå»æˆç¸¾\n",
                "    'horse_race_count', 'horse_avg_finish',\n",
                "    'horse_win_rate', 'horse_place_rate',\n",
                "    'horse_avg_last_3f', 'surface_match',\n",
                "    # é¨æ‰‹ã®æˆç¸¾\n",
                "    'jockey_race_count', 'jockey_win_rate', 'jockey_place_rate',\n",
                "    # èª¿æ•™å¸«ã®æˆç¸¾\n",
                "    'trainer_race_count', 'trainer_win_rate', 'trainer_place_rate',\n",
                "]\n",
                "\n",
                "# ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«\n",
                "FEATURE_COLS_WITH_ODDS = FEATURE_COLS_NO_ODDS + ['popularity', 'odds']\n",
                "\n",
                "print(\"ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«ç‰¹å¾´é‡:\", len(FEATURE_COLS_NO_ODDS), \"å€‹\")\n",
                "print(\"ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«ç‰¹å¾´é‡:\", len(FEATURE_COLS_WITH_ODDS), \"å€‹\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆæ¬ æå€¤ã‚’åŸ‹ã‚ã‚‹ï¼‰\n",
                "for col in FEATURE_COLS_WITH_ODDS:\n",
                "    if col in train_features.columns:\n",
                "        train_features[col] = train_features[col].fillna(0)\n",
                "        test_features[col] = test_features[col].fillna(0)\n",
                "\n",
                "train_clean = train_features.dropna(subset=['target'])\n",
                "test_clean = test_features.dropna(subset=['target'])\n",
                "\n",
                "print(f\"Train (clean): {len(train_clean):,}\")\n",
                "print(f\"Test (clean): {len(test_clean):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»è©•ä¾¡"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_and_evaluate(train_data, test_data, feature_cols, model_name):\n",
                "    \"\"\"ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨è©•ä¾¡\"\"\"\n",
                "    print(f\"\\n{'='*50}\")\n",
                "    print(f\"ğŸ¯ {model_name}\")\n",
                "    print(f\"{'='*50}\")\n",
                "    \n",
                "    X_train = train_data[feature_cols]\n",
                "    y_train = train_data['target']\n",
                "    X_test = test_data[feature_cols]\n",
                "    y_test = test_data['target']\n",
                "    \n",
                "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
                "        X_train, y_train, test_size=0.2, random_state=42\n",
                "    )\n",
                "    \n",
                "    params = {\n",
                "        'objective': 'binary',\n",
                "        'metric': 'auc',\n",
                "        'learning_rate': 0.05,\n",
                "        'num_leaves': 31,\n",
                "        'feature_fraction': 0.8,\n",
                "        'bagging_fraction': 0.8,\n",
                "        'bagging_freq': 5,\n",
                "        'verbose': -1,\n",
                "        'random_state': 42,\n",
                "    }\n",
                "    \n",
                "    train_ds = lgb.Dataset(X_tr, label=y_tr)\n",
                "    val_ds = lgb.Dataset(X_val, label=y_val, reference=train_ds)\n",
                "    \n",
                "    model = lgb.train(\n",
                "        params,\n",
                "        train_ds,\n",
                "        num_boost_round=1000,\n",
                "        valid_sets=[train_ds, val_ds],\n",
                "        valid_names=['train', 'valid'],\n",
                "        callbacks=[\n",
                "            lgb.early_stopping(stopping_rounds=50),\n",
                "            lgb.log_evaluation(period=0)\n",
                "        ]\n",
                "    )\n",
                "    \n",
                "    y_pred_proba = model.predict(X_test)\n",
                "    auc = roc_auc_score(y_test, y_pred_proba)\n",
                "    print(f\"\\nğŸ“Š Test AUC: {auc:.4f}\")\n",
                "    \n",
                "    test_with_pred = test_data.copy()\n",
                "    test_with_pred['pred_proba'] = y_pred_proba\n",
                "    \n",
                "    # çš„ä¸­ç‡ï¼ˆä¸Šä½3é ­ã®ä¸­ã«3ç€å†…é¦¬ãŒã„ã‚‹å‰²åˆï¼‰\n",
                "    def calc_hit(group, top_n=3):\n",
                "        top_preds = group.nlargest(top_n, 'pred_proba')\n",
                "        return (top_preds['finish_position'] <= 3).any()\n",
                "    \n",
                "    race_hit = test_with_pred.groupby('race_id').apply(calc_hit)\n",
                "    hit_rate = race_hit.mean()\n",
                "    print(f\"ğŸ¯ ä¸Šä½3é ­äºˆæ¸¬ã®çš„ä¸­ç‡: {hit_rate:.1%}\")\n",
                "    \n",
                "    # å˜å‹å›åç‡\n",
                "    def sim_returns(group):\n",
                "        top = group.nlargest(1, 'pred_proba').iloc[0]\n",
                "        return top['odds'] * 100 if top['finish_position'] == 1 else 0\n",
                "    \n",
                "    returns = test_with_pred.groupby('race_id').apply(sim_returns)\n",
                "    return_rate = returns.sum() / (len(returns) * 100) * 100\n",
                "    print(f\"ğŸ’° å˜å‹å›åç‡: {return_rate:.1f}%\")\n",
                "    \n",
                "    # ä¸‰é€£è¤‡çš„ä¸­ç‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆä¸Šä½5é ­ã‹ã‚‰3é ­ã‚’é¸ã¶ï¼‰\n",
                "    def calc_sanrenpuku_hit(group):\n",
                "        top5 = group.nlargest(5, 'pred_proba')\n",
                "        actual_top3 = group.nsmallest(3, 'finish_position')['horse_id'].values\n",
                "        pred_top5_ids = top5['horse_id'].values\n",
                "        # å®Ÿéš›ã®3ç€å†…é¦¬ã®ã†ã¡ã€äºˆæ¸¬ä¸Šä½5é ­ã«ä½•é ­å«ã¾ã‚Œã‚‹ã‹\n",
                "        matches = len(set(actual_top3) & set(pred_top5_ids))\n",
                "        return matches >= 3  # 3é ­å…¨ã¦å«ã¾ã‚Œã¦ã„ã‚Œã°çš„ä¸­\n",
                "    \n",
                "    sanren_hit = test_with_pred.groupby('race_id').apply(calc_sanrenpuku_hit)\n",
                "    sanren_rate = sanren_hit.mean()\n",
                "    print(f\"ğŸ‡ ä¸‰é€£è¤‡çš„ä¸­ç‡ï¼ˆä¸Šä½5é ­é¸æŠï¼‰: {sanren_rate:.1%}\")\n",
                "    \n",
                "    importance = pd.DataFrame({\n",
                "        'feature': feature_cols,\n",
                "        'importance': model.feature_importance()\n",
                "    }).sort_values('importance', ascending=False)\n",
                "    \n",
                "    return {\n",
                "        'model': model,\n",
                "        'auc': auc,\n",
                "        'hit_rate': hit_rate,\n",
                "        'return_rate': return_rate,\n",
                "        'sanren_rate': sanren_rate,\n",
                "        'importance': importance,\n",
                "        'predictions': test_with_pred\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_no_odds = train_and_evaluate(\n",
                "    train_clean, test_clean,\n",
                "    FEATURE_COLS_NO_ODDS,\n",
                "    \"ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«ï¼ˆç´”ç²‹äºˆæ¸¬ï¼‰\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_with_odds = train_and_evaluate(\n",
                "    train_clean, test_clean,\n",
                "    FEATURE_COLS_WITH_ODDS,\n",
                "    \"ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«ï¼ˆé€Ÿå ±ã‚ªãƒƒã‚ºè¾¼ã¿ï¼‰\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"ğŸ“Š ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚µãƒãƒªãƒ¼\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "comparison = pd.DataFrame({\n",
                "    'æŒ‡æ¨™': ['AUC', 'ä¸Šä½3é ­çš„ä¸­ç‡', 'ä¸‰é€£è¤‡çš„ä¸­ç‡ï¼ˆ5é ­é¸æŠï¼‰', 'å˜å‹å›åç‡'],\n",
                "    'ã‚ªãƒƒã‚ºãªã—': [\n",
                "        f\"{result_no_odds['auc']:.4f}\",\n",
                "        f\"{result_no_odds['hit_rate']:.1%}\",\n",
                "        f\"{result_no_odds['sanren_rate']:.1%}\",\n",
                "        f\"{result_no_odds['return_rate']:.1f}%\"\n",
                "    ],\n",
                "    'ã‚ªãƒƒã‚ºã‚ã‚Š': [\n",
                "        f\"{result_with_odds['auc']:.4f}\",\n",
                "        f\"{result_with_odds['hit_rate']:.1%}\",\n",
                "        f\"{result_with_odds['sanren_rate']:.1%}\",\n",
                "        f\"{result_with_odds['return_rate']:.1f}%\"\n",
                "    ]\n",
                "})\n",
                "\n",
                "print(comparison.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "\n",
                "for ax, (name, result) in zip(axes, [\n",
                "    ('ã‚ªãƒƒã‚ºãªã—ãƒ¢ãƒ‡ãƒ«', result_no_odds),\n",
                "    ('ã‚ªãƒƒã‚ºã‚ã‚Šãƒ¢ãƒ‡ãƒ«', result_with_odds)\n",
                "]):\n",
                "    imp = result['importance'].head(12)\n",
                "    ax.barh(imp['feature'], imp['importance'])\n",
                "    ax.set_xlabel('Importance')\n",
                "    ax.set_title(f'{name}\\nTop 12 Features')\n",
                "    ax.invert_yaxis()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. ãƒ¢ãƒ‡ãƒ«ä¿å­˜"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pickle\n",
                "\n",
                "with open(MODEL_DIR / 'model_no_odds.pkl', 'wb') as f:\n",
                "    pickle.dump(result_no_odds['model'], f)\n",
                "\n",
                "with open(MODEL_DIR / 'model_with_odds.pkl', 'wb') as f:\n",
                "    pickle.dump(result_with_odds['model'], f)\n",
                "\n",
                "config = {\n",
                "    'feature_cols_no_odds': FEATURE_COLS_NO_ODDS,\n",
                "    'feature_cols_with_odds': FEATURE_COLS_WITH_ODDS,\n",
                "    'train_end_year': TRAIN_END_YEAR,\n",
                "}\n",
                "\n",
                "with open(MODEL_DIR / 'model_config.pkl', 'wb') as f:\n",
                "    pickle.dump(config, f)\n",
                "\n",
                "print(\"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†\")\n",
                "print(f\"  - {MODEL_DIR / 'model_no_odds.pkl'}\")\n",
                "print(f\"  - {MODEL_DIR / 'model_with_odds.pkl'}\")\n",
                "print(f\"  - {MODEL_DIR / 'model_config.pkl'}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}